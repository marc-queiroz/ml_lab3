{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/marc-queiroz/ml_lab3/blob/master/inception_v4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AyRUnMu-buXU"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Keras requires TensorFlow 2.2 or higher. Install TensorFlow via `pip install tensorflow`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m~/.virtualenvs/ML/lib/python3.8/site-packages/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomRotation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-b405557bcfc4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_img\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ML/lib/python3.8/site-packages/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomRotation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     raise ImportError(\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0;34m'Keras requires TensorFlow 2.2 or higher. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         'Install TensorFlow via `pip install tensorflow`')\n",
      "\u001b[0;31mImportError\u001b[0m: Keras requires TensorFlow 2.2 or higher. Install TensorFlow via `pip install tensorflow`"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random as rn\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "from sklearn.metrics import f1_score as sklearn_f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "SAVED_MODEL_NAME = 'model.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DaxQD5tjJpXz"
   },
   "source": [
    "## IMPORTANDO OS DADOS DO GITHUB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "Q-ET-26UQgFm",
    "outputId": "a51e3617-de50-4dca-b640-34a6f4dc9894"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'ml_lab3'...\n",
      "remote: Enumerating objects: 20022, done.\u001b[K\n",
      "remote: Counting objects: 100% (20022/20022), done.\u001b[K\n",
      "remote: Compressing objects: 100% (20018/20018), done.\u001b[K\n",
      "remote: Total 44278 (delta 7), reused 20016 (delta 4), pack-reused 24256\u001b[K\n",
      "Receiving objects: 100% (44278/44278), 365.08 MiB | 28.89 MiB/s, done.\n",
      "Resolving deltas: 100% (21/21), done.\n",
      "Checking out files: 100% (55131/55131), done.\n"
     ]
    }
   ],
   "source": [
    "!rm -rf ml_lab3/\n",
    "!git clone https://github.com/marc-queiroz/ml_lab3 ml_lab3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TZK6raP3_k1b"
   },
   "source": [
    "## DEFININDO AS ENTRADAS\n",
    "\n",
    "Então, é necessário definir os arquivos de entrada obtidos através do GitHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ykl0sbD8_r54"
   },
   "outputs": [],
   "source": [
    "TRAIN_FILE = \"./ml_lab3/train.txt\"\n",
    "TEST_FILE = \"./ml_lab3/test.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "04wdIy9n_661"
   },
   "source": [
    "## DEFININDO AS FUNÇÕES AUXILIARES\n",
    "\n",
    "Neste ponto são definidas as funções auxiliares para a execução dos experimentos.**negrito**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "_vui_BFAAEju",
    "outputId": "aba6a43c-92ba-4b96-a758-dc3f725eab42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEFININDO AS FUNÇÕES DE PREPARAÇÃO DE DADOS - DONE 2020-09-06 23:52:15.869877\n"
     ]
    }
   ],
   "source": [
    "def resize_data(data, size, convert):\n",
    "\tif convert:\n",
    "\t\tdata_upscaled = np.zeros((data.shape[0], size[0], size[1], 3))\n",
    "\telse:\n",
    "\t\tdata_upscaled = np.zeros((data.shape[0], size[0], size[1]))\n",
    "\tfor i, img in enumerate(data):\n",
    "\t\tlarge_img = cv2.resize(img, dsize=(size[1], size[0]), interpolation=cv2.INTER_CUBIC)\n",
    "\t\tdata_upscaled[i] = large_img\n",
    "\treturn data_upscaled\n",
    "\n",
    "def load_images(image_paths, convert=False):\n",
    "\tx = []\n",
    "\ty = []\n",
    "\tfor image_path in image_paths:\t\t\n",
    "\t\tpath, label = image_path.split(' ')\t  \n",
    "\t\tpath= './ml_lab3/' + path\n",
    "\t\tif convert:\n",
    "\t\t\timage_pil = Image.open(path).convert('RGB') \n",
    "\t\telse:\n",
    "\t\t\timage_pil = Image.open(path).convert('L')\n",
    "\t\timg = np.array(image_pil, dtype=np.uint8)\n",
    "\t\tx.append(img)\n",
    "\t\ty.append([int(label)])\n",
    "\tx = np.array(x)\n",
    "\ty = np.array(y)\n",
    "\tif np.min(y) != 0: \n",
    "\t\ty = y-1\n",
    "\treturn x, y\n",
    "\n",
    "def load_dataset(train_file, test_file, resize, convert=False, size=(224,224)):\n",
    "\tarq = open(train_file, 'r')\n",
    "\ttexto = arq.read()\n",
    "\ttrain_paths = texto.split('\\n')\n",
    "\tprint ('Size:', size)\n",
    "\ttrain_paths.remove('')\n",
    "\ttrain_paths.sort()\n",
    "\tprint (\"Loading training set...\")\n",
    "\tx_train, y_train = load_images(train_paths, convert)\n",
    "\tarq = open(test_file, 'r')\n",
    "\ttexto = arq.read()\n",
    "\ttest_paths = texto.split('\\n')\n",
    "\ttest_paths.remove('')\n",
    "\ttest_paths.sort()\n",
    "\tprint (\"Loading testing set...\")\n",
    "\tx_test, y_test = load_images(test_paths, convert)\n",
    "\tif resize:\n",
    "\t\tprint (\"Resizing images...\")\n",
    "\t\tx_train = resize_data(x_train, size, convert)\n",
    "\t\tx_test = resize_data(x_test, size, convert)\n",
    "\tif not convert:\n",
    "\t\tx_train = x_train.reshape(x_train.shape[0], size[0], size[1], 1)\n",
    "\t\tx_test = x_test.reshape(x_test.shape[0], size[0], size[1], 1)\n",
    "\tprint (np.shape(x_train))\n",
    "\treturn (x_train, y_train), (x_test, y_test)\n",
    " \n",
    "def generate_labels(x_test, y_test):\n",
    "  labels = []\n",
    "  for i in range(len(x_test)):\n",
    "    labels.append(y_test[i][0])\n",
    "  return labels\n",
    "\n",
    "def normalize_images(x):\n",
    "  x = x.astype('float32')\n",
    "  x /= 255\n",
    "  return x\n",
    "\n",
    "def convert_vector(x, num_classes):\n",
    "  return keras.utils.to_categorical(x, num_classes)\n",
    "\n",
    "def fit_model(model, x_train, y_train, x_test, y_test, epochs, batch_size=128, verbose=1, steps_per_epoch=None):\n",
    "  return model.fit(x=x_train, y=y_train, epochs=epochs, batch_size=batch_size, validation_data=(x_test, y_test), verbose=verbose, steps_per_epoch=steps_per_epoch)\n",
    "\n",
    "def get_confusion_matrix(model, x_test, labels):\n",
    "\tpred = []\n",
    "\ty_pred = np.argmax(model.predict(x_test), axis=1)\t\n",
    "\tfor i in range(len(x_test)):\n",
    "\t  pred.append(y_pred[i])\n",
    "\treturn confusion_matrix(labels, pred)\n",
    "\n",
    "def plot_graphs(history, filename=None):\n",
    "\tacc = history.history['acc']\n",
    "\tval_acc = history.history['val_acc']\n",
    "\tloss = history.history['loss']\n",
    "\tval_loss = history.history['val_loss']\n",
    "\tepochs = range(len(acc))\n",
    "\tfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10,5))\n",
    "\tax1.plot(epochs, acc, 'b', label='Acurácia do treinamento')\n",
    "\tax1.plot(epochs, val_acc, 'r', label='Acurácia da validação')\n",
    "\tax1.set_title('Acurácia do treinamento e validação')\n",
    "\tax1.legend()\n",
    "\tax2.plot(epochs, loss, 'b', label='Perda do treinamento')\n",
    "\tax2.plot(epochs, val_loss, 'r', label='Perda da validação')\n",
    "\tax2.set_title('Perda do treinamento e validação')\n",
    "\tax2.legend()\n",
    "\tif (filename):\n",
    "\t\tfig.savefig(filename)\n",
    "\t\tfrom google.colab import files\n",
    "\t\tfiles.download(filename)\n",
    "\tplt.show()\n",
    "\n",
    "def extract_features(model, input_file, output_file, img_rows, img_cols, dir_dataset):\n",
    "\tcount = 0\n",
    "\tfile_input = open (input_file, 'r')\n",
    "\tinput = file_input.readlines()\n",
    "\tfile_input.close()\n",
    "\toutput = open(output_file, 'w')\n",
    "\t# model = InceptionV3(weights='imagenet', include_top=False)\n",
    "\tfor i in input:\n",
    "\t\tif count % 1001 == 0:\t\t\t\n",
    "\t\t\tstart = get_time()\n",
    "\t\tsample_name, sample_class = i.split()\n",
    "\t\timg_path = dir_dataset + sample_name\n",
    "\t\t# print(img_path)\n",
    "\t\timg = image.load_img(img_path, target_size=(img_rows,img_cols))\n",
    "\t\timg_data = image.img_to_array(img)\n",
    "\t\timg_data = np.expand_dims(img_data, axis=0)\n",
    "\t\timg_data = preprocess_input(img_data)\n",
    "\t\tinception_features = model.predict(img_data)\n",
    "\t\tfeatures_np = np.array(inception_features)\n",
    "\t\tfeatures_np = features_np.flatten()\n",
    "\t\toutput.write(sample_class+' ')\n",
    "\t\tfor j in range (features_np.size):\n",
    "\t\t\toutput.write(str(j+1)+':'+str(features_np[j])+' ')\n",
    "\t\toutput.write('\\n')\n",
    "\t\tif count % 1000 == 0:\n",
    "\t\t\tprint('count', count, 'time for 1000 files:', get_time() - start)\n",
    "\t\tcount = count + 1\n",
    "\tprint(features_np.size)\n",
    "\toutput.close()\n",
    " \n",
    "def round_float(value):\n",
    "\treturn float(\"{:.3f}\".format(value))\n",
    " \n",
    "def get_time():\n",
    "    return time.time()\n",
    "\n",
    "def get_time_diff(start_time):\n",
    "    end_time = time.time()\n",
    "    return round_float(end_time - start_time)\n",
    "\n",
    "def plot_confusion_matrix(cm, filename=None):\n",
    "\tfig = plt.figure(figsize=(10,10))\n",
    "\tax = fig.add_subplot(111)\n",
    "\tcax = ax.matshow(cm)\n",
    "\tfor (x, y), value in np.ndenumerate(cm):\n",
    "\t\tplt.text(x, y, f\"{value:.0f}\", va=\"center\", ha=\"center\")\n",
    "\tplt.title('Matriz de Confusão')\n",
    "\tfig.colorbar(cax)\n",
    "\tplt.xlabel('Predicted')\n",
    "\tplt.ylabel('True')\n",
    "\tif (filename):\n",
    "\t\tfig.savefig(filename)\n",
    "\t\tfrom google.colab import files\n",
    "\t\tfiles.download(filename)\n",
    "\tplt.show()\n",
    "\n",
    "print('DEFININDO AS FUNÇÕES DE PREPARAÇÃO DE DADOS - DONE', datetime.now())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nBLUfwPNbuXh"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import initializers\n",
    "from keras import regularizers\n",
    "from keras import constraints\n",
    "from keras import backend as K\n",
    "from keras.activations import elu\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.engine import Layer, InputSpec\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.layers import Dense, Conv2D, Flatten, GlobalAveragePooling2D, Dropout\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "class RAdam(keras.optimizers.Optimizer):\n",
    "    \"\"\"RAdam optimizer.\n",
    "    # Arguments\n",
    "        lr: float >= 0. Learning rate.\n",
    "        beta_1: float, 0 < beta < 1. Generally close to 1.\n",
    "        beta_2: float, 0 < beta < 1. Generally close to 1.\n",
    "        epsilon: float >= 0. Fuzz factor. If `None`, defaults to `K.epsilon()`.\n",
    "        decay: float >= 0. Learning rate decay over each update.\n",
    "        weight_decay: float >= 0. Weight decay for each param.\n",
    "        amsgrad: boolean. Whether to apply the AMSGrad variant of this\n",
    "            algorithm from the paper \"On the Convergence of Adam and\n",
    "            Beyond\".\n",
    "        total_steps: int >= 0. Total number of training steps. Enable warmup by setting a positive value.\n",
    "        warmup_proportion: 0 < warmup_proportion < 1. The proportion of increasing steps.\n",
    "        min_lr: float >= 0. Minimum learning rate after warmup.\n",
    "    # References\n",
    "        - [Adam - A Method for Stochastic Optimization](https://arxiv.org/abs/1412.6980v8)\n",
    "        - [On the Convergence of Adam and Beyond](https://openreview.net/forum?id=ryQu7f-RZ)\n",
    "        - [On The Variance Of The Adaptive Learning Rate And Beyond](https://arxiv.org/pdf/1908.03265v1.pdf)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, lr=0.001, beta_1=0.9, beta_2=0.999,\n",
    "                 epsilon=None, decay=0., weight_decay=0., amsgrad=False,\n",
    "                 total_steps=0, warmup_proportion=0.1, min_lr=0., **kwargs):\n",
    "        super(RAdam, self).__init__(**kwargs)\n",
    "        with K.name_scope(self.__class__.__name__):\n",
    "            self.iterations = K.variable(0, dtype='int64', name='iterations')\n",
    "            self.lr = K.variable(lr, name='lr')\n",
    "            self.beta_1 = K.variable(beta_1, name='beta_1')\n",
    "            self.beta_2 = K.variable(beta_2, name='beta_2')\n",
    "            self.decay = K.variable(decay, name='decay')\n",
    "            self.weight_decay = K.variable(weight_decay, name='weight_decay')\n",
    "            self.total_steps = K.variable(total_steps, name='total_steps')\n",
    "            self.warmup_proportion = K.variable(warmup_proportion, name='warmup_proportion')\n",
    "            self.min_lr = K.variable(lr, name='min_lr')\n",
    "        if epsilon is None:\n",
    "            epsilon = K.epsilon()\n",
    "        self.epsilon = epsilon\n",
    "        self.initial_decay = decay\n",
    "        self.initial_weight_decay = weight_decay\n",
    "        self.initial_total_steps = total_steps\n",
    "        self.amsgrad = amsgrad\n",
    "\n",
    "    def get_updates(self, loss, params):\n",
    "        grads = self.get_gradients(loss, params)\n",
    "        self.updates = [K.update_add(self.iterations, 1)]\n",
    "\n",
    "        lr = self.lr\n",
    "\n",
    "        if self.initial_decay > 0:\n",
    "            lr = lr * (1. / (1. + self.decay * K.cast(self.iterations, K.dtype(self.decay))))\n",
    "\n",
    "        t = K.cast(self.iterations, K.floatx()) + 1\n",
    "\n",
    "        if self.initial_total_steps > 0:\n",
    "            warmup_steps = self.total_steps * self.warmup_proportion\n",
    "            decay_steps = self.total_steps - warmup_steps\n",
    "            lr = K.switch(\n",
    "                t <= warmup_steps,\n",
    "                lr * (t / warmup_steps),\n",
    "                lr * (1.0 - K.minimum(t, decay_steps) / decay_steps),\n",
    "            )\n",
    "\n",
    "        ms = [K.zeros(K.int_shape(p), dtype=K.dtype(p), name='m_' + str(i)) for (i, p) in enumerate(params)]\n",
    "        vs = [K.zeros(K.int_shape(p), dtype=K.dtype(p), name='v_' + str(i)) for (i, p) in enumerate(params)]\n",
    "\n",
    "        if self.amsgrad:\n",
    "            vhats = [K.zeros(K.int_shape(p), dtype=K.dtype(p), name='vhat_' + str(i)) for (i, p) in enumerate(params)]\n",
    "        else:\n",
    "            vhats = [K.zeros(1, name='vhat_' + str(i)) for i in range(len(params))]\n",
    "\n",
    "        self.weights = [self.iterations] + ms + vs + vhats\n",
    "\n",
    "        beta_1_t = K.pow(self.beta_1, t)\n",
    "        beta_2_t = K.pow(self.beta_2, t)\n",
    "\n",
    "        sma_inf = 2.0 / (1.0 - self.beta_2) - 1.0\n",
    "        sma_t = sma_inf - 2.0 * t * beta_2_t / (1.0 - beta_2_t)\n",
    "\n",
    "        for p, g, m, v, vhat in zip(params, grads, ms, vs, vhats):\n",
    "            m_t = (self.beta_1 * m) + (1. - self.beta_1) * g\n",
    "            v_t = (self.beta_2 * v) + (1. - self.beta_2) * K.square(g)\n",
    "\n",
    "            m_corr_t = m_t / (1.0 - beta_1_t)\n",
    "            if self.amsgrad:\n",
    "                vhat_t = K.maximum(vhat, v_t)\n",
    "                v_corr_t = K.sqrt(vhat_t / (1.0 - beta_2_t) + self.epsilon)\n",
    "                self.updates.append(K.update(vhat, vhat_t))\n",
    "            else:\n",
    "                v_corr_t = K.sqrt(v_t / (1.0 - beta_2_t) + self.epsilon)\n",
    "\n",
    "            r_t = K.sqrt((sma_t - 4.0) / (sma_inf - 4.0) *\n",
    "                         (sma_t - 2.0) / (sma_inf - 2.0) *\n",
    "                         sma_inf / sma_t)\n",
    "\n",
    "            p_t = K.switch(sma_t > 5, r_t * m_corr_t / v_corr_t, m_corr_t)\n",
    "\n",
    "            if self.initial_weight_decay > 0:\n",
    "                p_t += self.weight_decay * p\n",
    "\n",
    "            p_t = p - lr * p_t\n",
    "\n",
    "            self.updates.append(K.update(m, m_t))\n",
    "            self.updates.append(K.update(v, v_t))\n",
    "            new_p = p_t\n",
    "\n",
    "            # Apply constraints.\n",
    "            if getattr(p, 'constraint', None) is not None:\n",
    "                new_p = p.constraint(new_p)\n",
    "\n",
    "            self.updates.append(K.update(p, new_p))\n",
    "        return self.updates\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'lr': float(K.get_value(self.lr)),\n",
    "            'beta_1': float(K.get_value(self.beta_1)),\n",
    "            'beta_2': float(K.get_value(self.beta_2)),\n",
    "            'decay': float(K.get_value(self.decay)),\n",
    "            'weight_decay': float(K.get_value(self.weight_decay)),\n",
    "            'epsilon': self.epsilon,\n",
    "            'amsgrad': self.amsgrad,\n",
    "            'total_steps': float(K.get_value(self.total_steps)),\n",
    "            'warmup_proportion': float(K.get_value(self.warmup_proportion)),\n",
    "            'min_lr': float(K.get_value(self.min_lr)),\n",
    "        }\n",
    "        base_config = super(RAdam, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309
    },
    "colab_type": "code",
    "id": "S8Ds-QzOh0NH",
    "outputId": "e930dd3f-dd73-4e8f-d0f8-0a642ebd307f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-09-06 23:31:15--  https://github.com/kentsommer/keras-inceptionV4/releases/download/2.1/inception-v4_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "Resolving github.com (github.com)... 140.82.121.4\n",
      "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://github-production-release-asset-2e65be.s3.amazonaws.com/79427137/6cd679be-1531-11e7-9343-6f05a04841ca?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20200906%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200906T233116Z&X-Amz-Expires=300&X-Amz-Signature=f3f95d8b710204249deb67e106524cdde9de596bb0f6f50052bace5a7955760e&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=79427137&response-content-disposition=attachment%3B%20filename%3Dinception-v4_weights_tf_dim_ordering_tf_kernels_notop.h5&response-content-type=application%2Foctet-stream [following]\n",
      "--2020-09-06 23:31:16--  https://github-production-release-asset-2e65be.s3.amazonaws.com/79427137/6cd679be-1531-11e7-9343-6f05a04841ca?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20200906%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200906T233116Z&X-Amz-Expires=300&X-Amz-Signature=f3f95d8b710204249deb67e106524cdde9de596bb0f6f50052bace5a7955760e&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=79427137&response-content-disposition=attachment%3B%20filename%3Dinception-v4_weights_tf_dim_ordering_tf_kernels_notop.h5&response-content-type=application%2Foctet-stream\n",
      "Resolving github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)... 52.216.141.244\n",
      "Connecting to github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)|52.216.141.244|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 165780176 (158M) [application/octet-stream]\n",
      "Saving to: ‘inception-v4_weights_tf_dim_ordering_tf_kernels_notop.h5.4’\n",
      "\n",
      "inception-v4_weight 100%[===================>] 158.10M  34.1MB/s    in 5.2s    \n",
      "\n",
      "2020-09-06 23:31:21 (30.4 MB/s) - ‘inception-v4_weights_tf_dim_ordering_tf_kernels_notop.h5.4’ saved [165780176/165780176]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget 'https://github.com/kentsommer/keras-inceptionV4/releases/download/2.1/inception-v4_weights_tf_dim_ordering_tf_kernels_notop.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "inwNxcv1Z6jC",
    "outputId": "c9383a5f-48ce-48c3-c5fd-22201c817f9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: (299, 299)\n",
      "Loading training set...\n",
      "Loading testing set...\n",
      "Resizing images...\n",
      "(1578, 299, 299, 3)\n",
      "LOADING DATA - DONE\n"
     ]
    }
   ],
   "source": [
    "## Star Time\n",
    "# checkpoint_time = get_time()\n",
    "\n",
    "## Definitions\n",
    "NUM_CLASSES = 12\n",
    "IMG_ROWS = 299\n",
    "IMG_COLS = 299\n",
    "EPOCHS = 128\n",
    "\n",
    "## Loading Inital Data\n",
    "(x_train, y_train), (x_test, y_test) = load_dataset(TRAIN_FILE, TEST_FILE, resize=True, convert=True, size=(IMG_ROWS, IMG_COLS))\n",
    "\n",
    "## Normalize images\n",
    "x_train = normalize_images(x_train)\n",
    "x_test = normalize_images(x_test)\n",
    "\n",
    "## Generating Labels for Confusion Matrix\n",
    "labels = generate_labels(x_test, y_test)\n",
    "\n",
    "## Convert class vectros to binary class matrices\n",
    "y_train = convert_vector(y_train, NUM_CLASSES)\n",
    "y_test = convert_vector(y_test, NUM_CLASSES)\n",
    "\n",
    "## Execution Time\n",
    "# print(f'Execution Time: {get_time_diff(checkpoint_time)}')\n",
    "\n",
    "print('LOADING DATA - DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kn3_NMckbuXn"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Copyright 2017 TensorFlow Authors and Kent Sommer\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "   http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License.\n",
    "'''\n",
    "import numpy as np\n",
    "\n",
    "# Sys\n",
    "import warnings\n",
    "# Keras Core\n",
    "from keras.layers.convolutional import MaxPooling2D, Convolution2D, AveragePooling2D\n",
    "from keras.layers import Input, Dropout, Dense, Flatten, Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.merge import concatenate\n",
    "from keras import regularizers\n",
    "from keras import initializers\n",
    "from keras.models import Model\n",
    "# Backend\n",
    "from keras import backend as K\n",
    "# Utils\n",
    "from keras.utils.layer_utils import convert_all_kernels_in_model\n",
    "from keras.utils.data_utils import get_file\n",
    "\n",
    "\n",
    "#########################################################################################\n",
    "# Implements the Inception Network v4 (http://arxiv.org/pdf/1602.07261v1.pdf) in Keras. #\n",
    "#########################################################################################\n",
    "\n",
    "WEIGHTS_PATH = 'https://github.com/kentsommer/keras-inceptionV4/releases/download/2.1/inception-v4_weights_tf_dim_ordering_tf_kernels.h5'\n",
    "WEIGHTS_PATH_NO_TOP = 'https://github.com/kentsommer/keras-inceptionV4/releases/download/2.1/inception-v4_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "\n",
    "\n",
    "def preprocess_input(x):\n",
    "    x = np.divide(x, 255.0)\n",
    "    x = np.subtract(x, 0.5)\n",
    "    x = np.multiply(x, 2.0)\n",
    "    return x\n",
    "\n",
    "\n",
    "def conv2d_bn(x, nb_filter, num_row, num_col,\n",
    "              padding='same', strides=(1, 1), use_bias=False):\n",
    "    \"\"\"\n",
    "    Utility function to apply conv + BN. \n",
    "    (Slightly modified from https://github.com/fchollet/keras/blob/master/keras/applications/inception_v3.py)\n",
    "    \"\"\"\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        channel_axis = 1\n",
    "    else:\n",
    "        channel_axis = -1\n",
    "    x = Convolution2D(nb_filter, (num_row, num_col),\n",
    "                      strides=strides,\n",
    "                      padding=padding,\n",
    "                      use_bias=use_bias,\n",
    "                      kernel_regularizer=regularizers.l2(0.00004),\n",
    "                      kernel_initializer=initializers.VarianceScaling(scale=2.0, mode='fan_in', distribution='normal', seed=None))(x)\n",
    "    x = BatchNormalization(axis=channel_axis, momentum=0.9997, scale=False)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def block_inception_a(input):\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        channel_axis = 1\n",
    "    else:\n",
    "        channel_axis = -1\n",
    "\n",
    "    branch_0 = conv2d_bn(input, 96, 1, 1)\n",
    "\n",
    "    branch_1 = conv2d_bn(input, 64, 1, 1)\n",
    "    branch_1 = conv2d_bn(branch_1, 96, 3, 3)\n",
    "\n",
    "    branch_2 = conv2d_bn(input, 64, 1, 1)\n",
    "    branch_2 = conv2d_bn(branch_2, 96, 3, 3)\n",
    "    branch_2 = conv2d_bn(branch_2, 96, 3, 3)\n",
    "\n",
    "    branch_3 = AveragePooling2D((3,3), strides=(1,1), padding='same')(input)\n",
    "    branch_3 = conv2d_bn(branch_3, 96, 1, 1)\n",
    "\n",
    "    x = concatenate([branch_0, branch_1, branch_2, branch_3], axis=channel_axis)\n",
    "    return x\n",
    "\n",
    "\n",
    "def block_reduction_a(input):\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        channel_axis = 1\n",
    "    else:\n",
    "        channel_axis = -1\n",
    "\n",
    "    branch_0 = conv2d_bn(input, 384, 3, 3, strides=(2,2), padding='valid')\n",
    "\n",
    "    branch_1 = conv2d_bn(input, 192, 1, 1)\n",
    "    branch_1 = conv2d_bn(branch_1, 224, 3, 3)\n",
    "    branch_1 = conv2d_bn(branch_1, 256, 3, 3, strides=(2,2), padding='valid')\n",
    "\n",
    "    branch_2 = MaxPooling2D((3,3), strides=(2,2), padding='valid')(input)\n",
    "\n",
    "    x = concatenate([branch_0, branch_1, branch_2], axis=channel_axis)\n",
    "    return x\n",
    "\n",
    "\n",
    "def block_inception_b(input):\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        channel_axis = 1\n",
    "    else:\n",
    "        channel_axis = -1\n",
    "\n",
    "    branch_0 = conv2d_bn(input, 384, 1, 1)\n",
    "\n",
    "    branch_1 = conv2d_bn(input, 192, 1, 1)\n",
    "    branch_1 = conv2d_bn(branch_1, 224, 1, 7)\n",
    "    branch_1 = conv2d_bn(branch_1, 256, 7, 1)\n",
    "\n",
    "    branch_2 = conv2d_bn(input, 192, 1, 1)\n",
    "    branch_2 = conv2d_bn(branch_2, 192, 7, 1)\n",
    "    branch_2 = conv2d_bn(branch_2, 224, 1, 7)\n",
    "    branch_2 = conv2d_bn(branch_2, 224, 7, 1)\n",
    "    branch_2 = conv2d_bn(branch_2, 256, 1, 7)\n",
    "\n",
    "    branch_3 = AveragePooling2D((3,3), strides=(1,1), padding='same')(input)\n",
    "    branch_3 = conv2d_bn(branch_3, 128, 1, 1)\n",
    "\n",
    "    x = concatenate([branch_0, branch_1, branch_2, branch_3], axis=channel_axis)\n",
    "    return x\n",
    "\n",
    "\n",
    "def block_reduction_b(input):\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        channel_axis = 1\n",
    "    else:\n",
    "        channel_axis = -1\n",
    "\n",
    "    branch_0 = conv2d_bn(input, 192, 1, 1)\n",
    "    branch_0 = conv2d_bn(branch_0, 192, 3, 3, strides=(2, 2), padding='valid')\n",
    "\n",
    "    branch_1 = conv2d_bn(input, 256, 1, 1)\n",
    "    branch_1 = conv2d_bn(branch_1, 256, 1, 7)\n",
    "    branch_1 = conv2d_bn(branch_1, 320, 7, 1)\n",
    "    branch_1 = conv2d_bn(branch_1, 320, 3, 3, strides=(2,2), padding='valid')\n",
    "\n",
    "    branch_2 = MaxPooling2D((3, 3), strides=(2, 2), padding='valid')(input)\n",
    "\n",
    "    x = concatenate([branch_0, branch_1, branch_2], axis=channel_axis)\n",
    "    return x\n",
    "\n",
    "\n",
    "def block_inception_c(input):\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        channel_axis = 1\n",
    "    else:\n",
    "        channel_axis = -1\n",
    "\n",
    "    branch_0 = conv2d_bn(input, 256, 1, 1)\n",
    "\n",
    "    branch_1 = conv2d_bn(input, 384, 1, 1)\n",
    "    branch_10 = conv2d_bn(branch_1, 256, 1, 3)\n",
    "    branch_11 = conv2d_bn(branch_1, 256, 3, 1)\n",
    "    branch_1 = concatenate([branch_10, branch_11], axis=channel_axis)\n",
    "\n",
    "\n",
    "    branch_2 = conv2d_bn(input, 384, 1, 1)\n",
    "    branch_2 = conv2d_bn(branch_2, 448, 3, 1)\n",
    "    branch_2 = conv2d_bn(branch_2, 512, 1, 3)\n",
    "    branch_20 = conv2d_bn(branch_2, 256, 1, 3)\n",
    "    branch_21 = conv2d_bn(branch_2, 256, 3, 1)\n",
    "    branch_2 = concatenate([branch_20, branch_21], axis=channel_axis)\n",
    "\n",
    "    branch_3 = AveragePooling2D((3, 3), strides=(1, 1), padding='same')(input)\n",
    "    branch_3 = conv2d_bn(branch_3, 256, 1, 1)\n",
    "\n",
    "    x = concatenate([branch_0, branch_1, branch_2, branch_3], axis=channel_axis)\n",
    "    return x\n",
    "\n",
    "\n",
    "def inception_v4_base(input):\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        channel_axis = 1\n",
    "    else:\n",
    "        channel_axis = -1\n",
    "\n",
    "    # Input Shape is 299 x 299 x 3 (th) or 3 x 299 x 299 (th)\n",
    "    net = conv2d_bn(input, 32, 3, 3, strides=(2,2), padding='valid')\n",
    "    net = conv2d_bn(net, 32, 3, 3, padding='valid')\n",
    "    net = conv2d_bn(net, 64, 3, 3)\n",
    "\n",
    "    branch_0 = MaxPooling2D((3,3), strides=(2,2), padding='valid')(net)\n",
    "\n",
    "    branch_1 = conv2d_bn(net, 96, 3, 3, strides=(2,2), padding='valid')\n",
    "\n",
    "    net = concatenate([branch_0, branch_1], axis=channel_axis)\n",
    "\n",
    "    branch_0 = conv2d_bn(net, 64, 1, 1)\n",
    "    branch_0 = conv2d_bn(branch_0, 96, 3, 3, padding='valid')\n",
    "\n",
    "    branch_1 = conv2d_bn(net, 64, 1, 1)\n",
    "    branch_1 = conv2d_bn(branch_1, 64, 1, 7)\n",
    "    branch_1 = conv2d_bn(branch_1, 64, 7, 1)\n",
    "    branch_1 = conv2d_bn(branch_1, 96, 3, 3, padding='valid')\n",
    "\n",
    "    net = concatenate([branch_0, branch_1], axis=channel_axis)\n",
    "\n",
    "    branch_0 = conv2d_bn(net, 192, 3, 3, strides=(2,2), padding='valid')\n",
    "    branch_1 = MaxPooling2D((3,3), strides=(2,2), padding='valid')(net)\n",
    "\n",
    "    net = concatenate([branch_0, branch_1], axis=channel_axis)\n",
    "\n",
    "    # 35 x 35 x 384\n",
    "    # 4 x Inception-A blocks\n",
    "    for idx in range(4):\n",
    "    \tnet = block_inception_a(net)\n",
    "\n",
    "    # 35 x 35 x 384\n",
    "    # Reduction-A block\n",
    "    net = block_reduction_a(net)\n",
    "\n",
    "    # 17 x 17 x 1024\n",
    "    # 7 x Inception-B blocks\n",
    "    for idx in range(7):\n",
    "    \tnet = block_inception_b(net)\n",
    "\n",
    "    # 17 x 17 x 1024\n",
    "    # Reduction-B block\n",
    "    net = block_reduction_b(net)\n",
    "\n",
    "    # 8 x 8 x 1536\n",
    "    # 3 x Inception-C blocks\n",
    "    for idx in range(3):\n",
    "    \tnet = block_inception_c(net)\n",
    "\n",
    "    return net\n",
    "\n",
    "\n",
    "def inception_v4(num_classes, dropout_keep_prob, weights, include_top):\n",
    "    '''\n",
    "    Creates the inception v4 network\n",
    "\n",
    "    Args:\n",
    "    \tnum_classes: number of classes\n",
    "    \tdropout_keep_prob: float, the fraction to keep before final layer.\n",
    "    \n",
    "    Returns: \n",
    "    \tlogits: the logits outputs of the model.\n",
    "    '''\n",
    "\n",
    "    # Input Shape is 299 x 299 x 3 (tf) or 3 x 299 x 299 (th)\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        inputs = Input((3, 299, 299))\n",
    "    else:\n",
    "        inputs = Input((299, 299, 3))\n",
    "\n",
    "    # Make inception base\n",
    "    x = inception_v4_base(inputs)\n",
    "\n",
    "\n",
    "    # Final pooling and prediction\n",
    "    if include_top:\n",
    "        # 1 x 1 x 1536\n",
    "        x = AveragePooling2D((8,8), padding='valid')(x)\n",
    "        x = Dropout(dropout_keep_prob)(x)\n",
    "        x = Flatten()(x)\n",
    "        # 1536\n",
    "        x = Dense(units=num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs, x, name='inception_v4')\n",
    "\n",
    "    # load weights\n",
    "    if weights == 'imagenet':\n",
    "        if K.image_data_format() == 'channels_first':\n",
    "            if K.backend() == 'tensorflow':\n",
    "                warnings.warn('You are using the TensorFlow backend, yet you '\n",
    "                              'are using the Theano '\n",
    "                              'image data format convention '\n",
    "                              '(`image_data_format=\"channels_first\"`). '\n",
    "                              'For best performance, set '\n",
    "                              '`image_data_format=\"channels_last\"` in '\n",
    "                              'your Keras config '\n",
    "                              'at ~/.keras/keras.json.')\n",
    "        if include_top:\n",
    "            weights_path = get_file(\n",
    "                'inception-v4_weights_tf_dim_ordering_tf_kernels.h5',\n",
    "                WEIGHTS_PATH,\n",
    "                cache_subdir='models',\n",
    "                md5_hash='9fe79d77f793fe874470d84ca6ba4a3b')\n",
    "        else:\n",
    "            weights_path = get_file(\n",
    "                'inception-v4_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
    "                WEIGHTS_PATH_NO_TOP,\n",
    "                cache_subdir='models',\n",
    "                md5_hash='9296b46b5971573064d12e4669110969')\n",
    "        model.load_weights(weights_path, by_name=True)\n",
    "    return model\n",
    "\n",
    "\n",
    "def create_model(num_classes=1001, dropout_prob=0.2, weights=None, include_top=False):\n",
    "    return inception_v4(num_classes, dropout_prob, weights, include_top)\n",
    "\n",
    "def get_model(num_classes=1001):\n",
    "  # ----------------------------------------------------------\n",
    "  incept_model = create_model(num_classes=1001, dropout_prob=0.2, weights=None, include_top=False)\n",
    "  incept_model.load_weights('inception-v4_weights_tf_dim_ordering_tf_kernels_notop.h5')\n",
    "\n",
    "  for l in incept_model.layers: \n",
    "      if l is not None: l.trainable = False \n",
    "\n",
    "  x = incept_model.output\n",
    "  x = GlobalAveragePooling2D(data_format='channels_last')(x)\n",
    "  x = BatchNormalization()(x)\n",
    "  #x = Dense(1024, activation='relu')(x)\n",
    "  #x = Dropout(0.2)(x)\n",
    "  x = Dense(512, activation='relu')(x)\n",
    "  #x = Dropout(0.2)(x)\n",
    "  predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "  model = Model(inputs=incept_model.input, outputs=predictions)        \n",
    "  model.summary()\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bjqRd3W5buXr"
   },
   "outputs": [],
   "source": [
    "# ----- call back functions ------------------\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0.0002, patience=10, verbose=1, mode='auto')\n",
    "# Reducing the Learning Rate if result is not improving. \n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', min_delta=0.0004, patience=5, factor=0.1, min_lr=1e-6, mode='auto', verbose=1)\n",
    "# ---------------------------------------------- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 547
    },
    "colab_type": "code",
    "id": "c4VbnEL3buXu",
    "outputId": "a712ef83-10b8-44a4-acbf-d6eff4687750"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "100/100 [==============================] - 15s 148ms/step - loss: 0.8199 - mse: 0.0743 - acc: 0.2371 - val_loss: 0.8166 - val_mse: 0.0709 - val_acc: 0.3192\n",
      "Epoch 2/40\n",
      "100/100 [==============================] - 11s 115ms/step - loss: 0.7997 - mse: 0.0541 - acc: 0.5019 - val_loss: 0.8056 - val_mse: 0.0600 - val_acc: 0.4863\n",
      "Epoch 3/40\n",
      " 14/100 [===>..........................] - ETA: 7s - loss: 0.7906 - mse: 0.0450 - acc: 0.6116"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-dfe8c7cdf8c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;31m## Star Time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0mcheckpoint_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_lr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;31m# H = model.fit(x=x_train, y=y_train, epochs=40, steps_per_epoch=100, validation_data=(x_test, y_test), callbacks=[kappa_metrics, early_stop, reduce_lr], verbose=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.utils import class_weight\n",
    "BATCH_SIZE=32\n",
    "SAVED_MODEL_NAME=\"my_model.d5\"\n",
    "# Y_train = df_train.diagnosis.values\n",
    "# print(y_train)\n",
    "# class_weight_ = class_weight.compute_class_weight('balanced',np.unique(y_train),y_train)\n",
    "# print(class_weight_)\n",
    "# ---------------------------------------------- \n",
    "def get_preds_and_labels(model, generator):\n",
    "    \"\"\"\n",
    "    Get predictions and labels from the generator\n",
    "    \"\"\"\n",
    "    preds = []\n",
    "    labels = []\n",
    "    for _ in range(int(np.ceil(generator.samples / BATCH_SIZE))):\n",
    "        x, y = next(generator)\n",
    "        preds.append(model.predict(x))\n",
    "        labels.append(y)\n",
    "    # Flatten list of numpy arrays\n",
    "    return np.concatenate(preds).ravel(), np.concatenate(labels).ravel()\n",
    "# ---------------------------------------------- \n",
    "class Metrics(Callback):\n",
    "    \"\"\"\n",
    "    A custom Keras callback for saving the best model\n",
    "    according to the Quadratic Weighted Kappa (QWK) metric\n",
    "    \"\"\"\n",
    "    def on_train_begin(self, logs={}):\n",
    "        \"\"\"\n",
    "        Initialize list of QWK scores on validation data\n",
    "        \"\"\"\n",
    "        self.val_kappas = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \"\"\"\n",
    "        Gets QWK score on the validation data\n",
    "        \"\"\"\n",
    "        # Get predictions and convert to integers\n",
    "        y_pred, labels = get_preds_and_labels(model, valid_generator)\n",
    "        y_pred = np.rint(y_pred).astype(np.uint8).clip(0, 4)\n",
    "        # We can use sklearns implementation of QWK straight out of the box\n",
    "        # as long as we specify weights as 'quadratic'\n",
    "        _val_kappa = cohen_kappa_score(labels, y_pred, weights='quadratic')\n",
    "        self.val_kappas.append(_val_kappa)\n",
    "        print(f\"val_kappa: {round(_val_kappa, 4)}\")\n",
    "        if _val_kappa == max(self.val_kappas):\n",
    "            print(\"Validation Kappa has improved. Saving model.\")\n",
    "            self.model.save(SAVED_MODEL_NAME)\n",
    "        return\n",
    "# ---------------------------------------------- \n",
    "kappa_metrics = Metrics()\n",
    "#from keras.utils import multi_gpu_model\n",
    "\n",
    "# df_train.id_code=df_train.id_code.apply(lambda x: x+\".png\")\n",
    "# df_train['diagnosis'] = df_train['diagnosis'].astype('str')\n",
    "# \n",
    "# df_test.id_code=df_test.id_code.apply(lambda x: x+\".png\")\n",
    "# \n",
    "# aug = ImageDataGenerator(rescale=1./255, validation_split=0.2, horizontal_flip=True, \n",
    "#                          vertical_flip=True, rotation_range=120, zoom_range=0.1, \n",
    "#                          width_shift_range=0.2, shear_range=0.15, fill_mode='nearest')\n",
    "# \n",
    "# train_generator=aug.flow_from_dataframe(dataframe=df_train, \n",
    "#                                         #directory=\"../input/aptos2019-blindness-detection/train_images/\",\n",
    "#                                         directory=\"../input/train_images/\",\n",
    "#                                         x_col=\"id_code\", y_col=\"diagnosis\",\n",
    "#                                         batch_size=BATCH_SIZE, class_mode=\"categorical\", target_size=(299, 299),\n",
    "#                                         #preprocessing_function=circle_crop,\n",
    "#                                         subset='training', shaffle=False, seed=SEED)\n",
    "# \n",
    "# valid_generator=aug.flow_from_dataframe(dataframe=df_train, \n",
    "#                                         #directory=\"../input/aptos2019-blindness-detection/train_images/\",\n",
    "#                                         directory=\"../input/train_images/\",\n",
    "#                                         x_col=\"id_code\", y_col=\"diagnosis\",\n",
    "#                                         batch_size=BATCH_SIZE, class_mode=\"categorical\", target_size=(299, 299),\n",
    "#                                         #preprocessing_function=circle_crop,\n",
    "#                                         subset='validation', shaffle=False, seed=SEED)\n",
    "# \n",
    "# model.compile(loss='mse', optimizer=RAdam(lr=0.00005, name=None), metrics=['mse', 'acc'])\n",
    "model = get_model(num_classes=NUM_CLASSES)\n",
    "model.compile(loss='mse', optimizer=keras.optimizers.Adam(learning_rate=0.00005), metrics=['mse', 'acc'])\n",
    "# (x=x_train, y=y_train, epochs=epochs, batch_size=batch_size, validation_data=(x_test, y_test), verbose=verbose)\n",
    "## Star Time\n",
    "checkpoint_time = get_time()\n",
    "history = model.fit(x=x_train, y=y_train, epochs=40, steps_per_epoch=100, validation_data=(x_test, y_test), callbacks=[early_stop, reduce_lr], verbose=1)\n",
    "# H = model.fit(x=x_train, y=y_train, epochs=40, steps_per_epoch=100, validation_data=(x_test, y_test), callbacks=[kappa_metrics, early_stop, reduce_lr], verbose=1)\n",
    "# \n",
    "# H = model.fit_generator(generator=train_generator, validation_steps=50, \n",
    "#                          validation_data=valid_generator,\n",
    "#                          callbacks=[kappa_metrics, early_stop, reduce_lr],\n",
    "#                          steps_per_epoch=100, \n",
    "#                          epochs=40, \n",
    "#                          verbose=1)\n",
    "\n",
    "#                         class_weight = class_weight_)\n",
    "# -------------------------------------------\n",
    "#tlog(\"done\")\n",
    "\n",
    "## Getting Score\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "## Loss\n",
    "print('Loss:', score[0])\n",
    "\n",
    "## Accuracy\n",
    "print('Accuracy:', score[1])\n",
    "\n",
    "## Execution Time\n",
    "print(f'Execution Time: {get_time_diff(checkpoint_time)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Umq8Ym5GkVIS",
    "outputId": "d50b69fe-89db-430f-f4b5-19aba255d958"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: (299, 299)\n",
      "Loading training set...\n",
      "Loading testing set...\n",
      "Resizing images...\n",
      "(1578, 299, 299, 3)\n",
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)             (None, 149, 149, 32) 864         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_150 (BatchN (None, 149, 149, 32) 96          conv2d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_149 (Activation)     (None, 149, 149, 32) 0           batch_normalization_150[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)             (None, 147, 147, 32) 9216        activation_149[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_151 (BatchN (None, 147, 147, 32) 96          conv2d_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_150 (Activation)     (None, 147, 147, 32) 0           batch_normalization_151[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)             (None, 147, 147, 64) 18432       activation_150[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_152 (BatchN (None, 147, 147, 64) 192         conv2d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_151 (Activation)     (None, 147, 147, 64) 0           batch_normalization_152[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)             (None, 73, 73, 96)   55296       activation_151[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_153 (BatchN (None, 73, 73, 96)   288         conv2d_152[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 73, 73, 64)   0           activation_151[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_152 (Activation)     (None, 73, 73, 96)   0           batch_normalization_153[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_25 (Concatenate)    (None, 73, 73, 160)  0           max_pooling2d_4[0][0]            \n",
      "                                                                 activation_152[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)             (None, 73, 73, 64)   10240       concatenate_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_156 (BatchN (None, 73, 73, 64)   192         conv2d_155[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_155 (Activation)     (None, 73, 73, 64)   0           batch_normalization_156[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_156 (Conv2D)             (None, 73, 73, 64)   28672       activation_155[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_157 (BatchN (None, 73, 73, 64)   192         conv2d_156[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_156 (Activation)     (None, 73, 73, 64)   0           batch_normalization_157[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_153 (Conv2D)             (None, 73, 73, 64)   10240       concatenate_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_157 (Conv2D)             (None, 73, 73, 64)   28672       activation_156[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_154 (BatchN (None, 73, 73, 64)   192         conv2d_153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_158 (BatchN (None, 73, 73, 64)   192         conv2d_157[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_153 (Activation)     (None, 73, 73, 64)   0           batch_normalization_154[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_157 (Activation)     (None, 73, 73, 64)   0           batch_normalization_158[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)             (None, 71, 71, 96)   55296       activation_153[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_158 (Conv2D)             (None, 71, 71, 96)   55296       activation_157[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_155 (BatchN (None, 71, 71, 96)   288         conv2d_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_159 (BatchN (None, 71, 71, 96)   288         conv2d_158[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_154 (Activation)     (None, 71, 71, 96)   0           batch_normalization_155[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_158 (Activation)     (None, 71, 71, 96)   0           batch_normalization_159[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_26 (Concatenate)    (None, 71, 71, 192)  0           activation_154[0][0]             \n",
      "                                                                 activation_158[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_159 (Conv2D)             (None, 35, 35, 192)  331776      concatenate_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_160 (BatchN (None, 35, 35, 192)  576         conv2d_159[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_159 (Activation)     (None, 35, 35, 192)  0           batch_normalization_160[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 35, 35, 192)  0           concatenate_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_27 (Concatenate)    (None, 35, 35, 384)  0           activation_159[0][0]             \n",
      "                                                                 max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_163 (Conv2D)             (None, 35, 35, 64)   24576       concatenate_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_164 (BatchN (None, 35, 35, 64)   192         conv2d_163[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_163 (Activation)     (None, 35, 35, 64)   0           batch_normalization_164[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_161 (Conv2D)             (None, 35, 35, 64)   24576       concatenate_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_164 (Conv2D)             (None, 35, 35, 96)   55296       activation_163[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_162 (BatchN (None, 35, 35, 64)   192         conv2d_161[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_165 (BatchN (None, 35, 35, 96)   288         conv2d_164[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_161 (Activation)     (None, 35, 35, 64)   0           batch_normalization_162[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_164 (Activation)     (None, 35, 35, 96)   0           batch_normalization_165[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_14 (AveragePo (None, 35, 35, 384)  0           concatenate_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_160 (Conv2D)             (None, 35, 35, 96)   36864       concatenate_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_162 (Conv2D)             (None, 35, 35, 96)   55296       activation_161[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_165 (Conv2D)             (None, 35, 35, 96)   82944       activation_164[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_166 (Conv2D)             (None, 35, 35, 96)   36864       average_pooling2d_14[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_161 (BatchN (None, 35, 35, 96)   288         conv2d_160[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_163 (BatchN (None, 35, 35, 96)   288         conv2d_162[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_166 (BatchN (None, 35, 35, 96)   288         conv2d_165[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_167 (BatchN (None, 35, 35, 96)   288         conv2d_166[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_160 (Activation)     (None, 35, 35, 96)   0           batch_normalization_161[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_162 (Activation)     (None, 35, 35, 96)   0           batch_normalization_163[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_165 (Activation)     (None, 35, 35, 96)   0           batch_normalization_166[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_166 (Activation)     (None, 35, 35, 96)   0           batch_normalization_167[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_28 (Concatenate)    (None, 35, 35, 384)  0           activation_160[0][0]             \n",
      "                                                                 activation_162[0][0]             \n",
      "                                                                 activation_165[0][0]             \n",
      "                                                                 activation_166[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_170 (Conv2D)             (None, 35, 35, 64)   24576       concatenate_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_171 (BatchN (None, 35, 35, 64)   192         conv2d_170[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_170 (Activation)     (None, 35, 35, 64)   0           batch_normalization_171[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_168 (Conv2D)             (None, 35, 35, 64)   24576       concatenate_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_171 (Conv2D)             (None, 35, 35, 96)   55296       activation_170[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_169 (BatchN (None, 35, 35, 64)   192         conv2d_168[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_172 (BatchN (None, 35, 35, 96)   288         conv2d_171[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_168 (Activation)     (None, 35, 35, 64)   0           batch_normalization_169[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_171 (Activation)     (None, 35, 35, 96)   0           batch_normalization_172[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_15 (AveragePo (None, 35, 35, 384)  0           concatenate_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_167 (Conv2D)             (None, 35, 35, 96)   36864       concatenate_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_169 (Conv2D)             (None, 35, 35, 96)   55296       activation_168[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_172 (Conv2D)             (None, 35, 35, 96)   82944       activation_171[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_173 (Conv2D)             (None, 35, 35, 96)   36864       average_pooling2d_15[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_168 (BatchN (None, 35, 35, 96)   288         conv2d_167[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_170 (BatchN (None, 35, 35, 96)   288         conv2d_169[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_173 (BatchN (None, 35, 35, 96)   288         conv2d_172[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_174 (BatchN (None, 35, 35, 96)   288         conv2d_173[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_167 (Activation)     (None, 35, 35, 96)   0           batch_normalization_168[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_169 (Activation)     (None, 35, 35, 96)   0           batch_normalization_170[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_172 (Activation)     (None, 35, 35, 96)   0           batch_normalization_173[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_173 (Activation)     (None, 35, 35, 96)   0           batch_normalization_174[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_29 (Concatenate)    (None, 35, 35, 384)  0           activation_167[0][0]             \n",
      "                                                                 activation_169[0][0]             \n",
      "                                                                 activation_172[0][0]             \n",
      "                                                                 activation_173[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_177 (Conv2D)             (None, 35, 35, 64)   24576       concatenate_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_178 (BatchN (None, 35, 35, 64)   192         conv2d_177[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_177 (Activation)     (None, 35, 35, 64)   0           batch_normalization_178[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_175 (Conv2D)             (None, 35, 35, 64)   24576       concatenate_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_178 (Conv2D)             (None, 35, 35, 96)   55296       activation_177[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_176 (BatchN (None, 35, 35, 64)   192         conv2d_175[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_179 (BatchN (None, 35, 35, 96)   288         conv2d_178[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_175 (Activation)     (None, 35, 35, 64)   0           batch_normalization_176[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_178 (Activation)     (None, 35, 35, 96)   0           batch_normalization_179[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_16 (AveragePo (None, 35, 35, 384)  0           concatenate_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_174 (Conv2D)             (None, 35, 35, 96)   36864       concatenate_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_176 (Conv2D)             (None, 35, 35, 96)   55296       activation_175[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_179 (Conv2D)             (None, 35, 35, 96)   82944       activation_178[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_180 (Conv2D)             (None, 35, 35, 96)   36864       average_pooling2d_16[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_175 (BatchN (None, 35, 35, 96)   288         conv2d_174[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_177 (BatchN (None, 35, 35, 96)   288         conv2d_176[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_180 (BatchN (None, 35, 35, 96)   288         conv2d_179[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_181 (BatchN (None, 35, 35, 96)   288         conv2d_180[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_174 (Activation)     (None, 35, 35, 96)   0           batch_normalization_175[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_176 (Activation)     (None, 35, 35, 96)   0           batch_normalization_177[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_179 (Activation)     (None, 35, 35, 96)   0           batch_normalization_180[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_180 (Activation)     (None, 35, 35, 96)   0           batch_normalization_181[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_30 (Concatenate)    (None, 35, 35, 384)  0           activation_174[0][0]             \n",
      "                                                                 activation_176[0][0]             \n",
      "                                                                 activation_179[0][0]             \n",
      "                                                                 activation_180[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_184 (Conv2D)             (None, 35, 35, 64)   24576       concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_185 (BatchN (None, 35, 35, 64)   192         conv2d_184[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_184 (Activation)     (None, 35, 35, 64)   0           batch_normalization_185[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_182 (Conv2D)             (None, 35, 35, 64)   24576       concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_185 (Conv2D)             (None, 35, 35, 96)   55296       activation_184[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_183 (BatchN (None, 35, 35, 64)   192         conv2d_182[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_186 (BatchN (None, 35, 35, 96)   288         conv2d_185[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_182 (Activation)     (None, 35, 35, 64)   0           batch_normalization_183[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_185 (Activation)     (None, 35, 35, 96)   0           batch_normalization_186[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_17 (AveragePo (None, 35, 35, 384)  0           concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_181 (Conv2D)             (None, 35, 35, 96)   36864       concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_183 (Conv2D)             (None, 35, 35, 96)   55296       activation_182[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_186 (Conv2D)             (None, 35, 35, 96)   82944       activation_185[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_187 (Conv2D)             (None, 35, 35, 96)   36864       average_pooling2d_17[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_182 (BatchN (None, 35, 35, 96)   288         conv2d_181[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_184 (BatchN (None, 35, 35, 96)   288         conv2d_183[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_187 (BatchN (None, 35, 35, 96)   288         conv2d_186[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_188 (BatchN (None, 35, 35, 96)   288         conv2d_187[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_181 (Activation)     (None, 35, 35, 96)   0           batch_normalization_182[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_183 (Activation)     (None, 35, 35, 96)   0           batch_normalization_184[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_186 (Activation)     (None, 35, 35, 96)   0           batch_normalization_187[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_187 (Activation)     (None, 35, 35, 96)   0           batch_normalization_188[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_31 (Concatenate)    (None, 35, 35, 384)  0           activation_181[0][0]             \n",
      "                                                                 activation_183[0][0]             \n",
      "                                                                 activation_186[0][0]             \n",
      "                                                                 activation_187[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_189 (Conv2D)             (None, 35, 35, 192)  73728       concatenate_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_190 (BatchN (None, 35, 35, 192)  576         conv2d_189[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_189 (Activation)     (None, 35, 35, 192)  0           batch_normalization_190[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_190 (Conv2D)             (None, 35, 35, 224)  387072      activation_189[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_191 (BatchN (None, 35, 35, 224)  672         conv2d_190[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_190 (Activation)     (None, 35, 35, 224)  0           batch_normalization_191[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_188 (Conv2D)             (None, 17, 17, 384)  1327104     concatenate_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_191 (Conv2D)             (None, 17, 17, 256)  516096      activation_190[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_189 (BatchN (None, 17, 17, 384)  1152        conv2d_188[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_192 (BatchN (None, 17, 17, 256)  768         conv2d_191[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_188 (Activation)     (None, 17, 17, 384)  0           batch_normalization_189[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_191 (Activation)     (None, 17, 17, 256)  0           batch_normalization_192[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 17, 17, 384)  0           concatenate_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_32 (Concatenate)    (None, 17, 17, 1024) 0           activation_188[0][0]             \n",
      "                                                                 activation_191[0][0]             \n",
      "                                                                 max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_196 (Conv2D)             (None, 17, 17, 192)  196608      concatenate_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_197 (BatchN (None, 17, 17, 192)  576         conv2d_196[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_196 (Activation)     (None, 17, 17, 192)  0           batch_normalization_197[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_197 (Conv2D)             (None, 17, 17, 192)  258048      activation_196[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_198 (BatchN (None, 17, 17, 192)  576         conv2d_197[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_197 (Activation)     (None, 17, 17, 192)  0           batch_normalization_198[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_193 (Conv2D)             (None, 17, 17, 192)  196608      concatenate_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_198 (Conv2D)             (None, 17, 17, 224)  301056      activation_197[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_194 (BatchN (None, 17, 17, 192)  576         conv2d_193[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_199 (BatchN (None, 17, 17, 224)  672         conv2d_198[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_193 (Activation)     (None, 17, 17, 192)  0           batch_normalization_194[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_198 (Activation)     (None, 17, 17, 224)  0           batch_normalization_199[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_194 (Conv2D)             (None, 17, 17, 224)  301056      activation_193[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_199 (Conv2D)             (None, 17, 17, 224)  351232      activation_198[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_195 (BatchN (None, 17, 17, 224)  672         conv2d_194[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_200 (BatchN (None, 17, 17, 224)  672         conv2d_199[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_194 (Activation)     (None, 17, 17, 224)  0           batch_normalization_195[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_199 (Activation)     (None, 17, 17, 224)  0           batch_normalization_200[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_18 (AveragePo (None, 17, 17, 1024) 0           concatenate_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_192 (Conv2D)             (None, 17, 17, 384)  393216      concatenate_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_195 (Conv2D)             (None, 17, 17, 256)  401408      activation_194[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_200 (Conv2D)             (None, 17, 17, 256)  401408      activation_199[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_201 (Conv2D)             (None, 17, 17, 128)  131072      average_pooling2d_18[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_193 (BatchN (None, 17, 17, 384)  1152        conv2d_192[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_196 (BatchN (None, 17, 17, 256)  768         conv2d_195[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_201 (BatchN (None, 17, 17, 256)  768         conv2d_200[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_202 (BatchN (None, 17, 17, 128)  384         conv2d_201[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_192 (Activation)     (None, 17, 17, 384)  0           batch_normalization_193[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_195 (Activation)     (None, 17, 17, 256)  0           batch_normalization_196[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_200 (Activation)     (None, 17, 17, 256)  0           batch_normalization_201[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_201 (Activation)     (None, 17, 17, 128)  0           batch_normalization_202[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_33 (Concatenate)    (None, 17, 17, 1024) 0           activation_192[0][0]             \n",
      "                                                                 activation_195[0][0]             \n",
      "                                                                 activation_200[0][0]             \n",
      "                                                                 activation_201[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_206 (Conv2D)             (None, 17, 17, 192)  196608      concatenate_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_207 (BatchN (None, 17, 17, 192)  576         conv2d_206[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_206 (Activation)     (None, 17, 17, 192)  0           batch_normalization_207[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_207 (Conv2D)             (None, 17, 17, 192)  258048      activation_206[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_208 (BatchN (None, 17, 17, 192)  576         conv2d_207[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_207 (Activation)     (None, 17, 17, 192)  0           batch_normalization_208[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_203 (Conv2D)             (None, 17, 17, 192)  196608      concatenate_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_208 (Conv2D)             (None, 17, 17, 224)  301056      activation_207[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_204 (BatchN (None, 17, 17, 192)  576         conv2d_203[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_209 (BatchN (None, 17, 17, 224)  672         conv2d_208[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_203 (Activation)     (None, 17, 17, 192)  0           batch_normalization_204[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_208 (Activation)     (None, 17, 17, 224)  0           batch_normalization_209[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_204 (Conv2D)             (None, 17, 17, 224)  301056      activation_203[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_209 (Conv2D)             (None, 17, 17, 224)  351232      activation_208[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_205 (BatchN (None, 17, 17, 224)  672         conv2d_204[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_210 (BatchN (None, 17, 17, 224)  672         conv2d_209[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_204 (Activation)     (None, 17, 17, 224)  0           batch_normalization_205[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_209 (Activation)     (None, 17, 17, 224)  0           batch_normalization_210[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_19 (AveragePo (None, 17, 17, 1024) 0           concatenate_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_202 (Conv2D)             (None, 17, 17, 384)  393216      concatenate_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_205 (Conv2D)             (None, 17, 17, 256)  401408      activation_204[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_210 (Conv2D)             (None, 17, 17, 256)  401408      activation_209[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_211 (Conv2D)             (None, 17, 17, 128)  131072      average_pooling2d_19[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_203 (BatchN (None, 17, 17, 384)  1152        conv2d_202[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_206 (BatchN (None, 17, 17, 256)  768         conv2d_205[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_211 (BatchN (None, 17, 17, 256)  768         conv2d_210[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_212 (BatchN (None, 17, 17, 128)  384         conv2d_211[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_202 (Activation)     (None, 17, 17, 384)  0           batch_normalization_203[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_205 (Activation)     (None, 17, 17, 256)  0           batch_normalization_206[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_210 (Activation)     (None, 17, 17, 256)  0           batch_normalization_211[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_211 (Activation)     (None, 17, 17, 128)  0           batch_normalization_212[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_34 (Concatenate)    (None, 17, 17, 1024) 0           activation_202[0][0]             \n",
      "                                                                 activation_205[0][0]             \n",
      "                                                                 activation_210[0][0]             \n",
      "                                                                 activation_211[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_216 (Conv2D)             (None, 17, 17, 192)  196608      concatenate_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_217 (BatchN (None, 17, 17, 192)  576         conv2d_216[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_216 (Activation)     (None, 17, 17, 192)  0           batch_normalization_217[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_217 (Conv2D)             (None, 17, 17, 192)  258048      activation_216[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_218 (BatchN (None, 17, 17, 192)  576         conv2d_217[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_217 (Activation)     (None, 17, 17, 192)  0           batch_normalization_218[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_213 (Conv2D)             (None, 17, 17, 192)  196608      concatenate_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_218 (Conv2D)             (None, 17, 17, 224)  301056      activation_217[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_214 (BatchN (None, 17, 17, 192)  576         conv2d_213[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_219 (BatchN (None, 17, 17, 224)  672         conv2d_218[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_213 (Activation)     (None, 17, 17, 192)  0           batch_normalization_214[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_218 (Activation)     (None, 17, 17, 224)  0           batch_normalization_219[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_214 (Conv2D)             (None, 17, 17, 224)  301056      activation_213[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_219 (Conv2D)             (None, 17, 17, 224)  351232      activation_218[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_215 (BatchN (None, 17, 17, 224)  672         conv2d_214[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_220 (BatchN (None, 17, 17, 224)  672         conv2d_219[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_214 (Activation)     (None, 17, 17, 224)  0           batch_normalization_215[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_219 (Activation)     (None, 17, 17, 224)  0           batch_normalization_220[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_20 (AveragePo (None, 17, 17, 1024) 0           concatenate_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_212 (Conv2D)             (None, 17, 17, 384)  393216      concatenate_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_215 (Conv2D)             (None, 17, 17, 256)  401408      activation_214[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_220 (Conv2D)             (None, 17, 17, 256)  401408      activation_219[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_221 (Conv2D)             (None, 17, 17, 128)  131072      average_pooling2d_20[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_213 (BatchN (None, 17, 17, 384)  1152        conv2d_212[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_216 (BatchN (None, 17, 17, 256)  768         conv2d_215[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_221 (BatchN (None, 17, 17, 256)  768         conv2d_220[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_222 (BatchN (None, 17, 17, 128)  384         conv2d_221[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_212 (Activation)     (None, 17, 17, 384)  0           batch_normalization_213[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_215 (Activation)     (None, 17, 17, 256)  0           batch_normalization_216[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_220 (Activation)     (None, 17, 17, 256)  0           batch_normalization_221[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_221 (Activation)     (None, 17, 17, 128)  0           batch_normalization_222[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_35 (Concatenate)    (None, 17, 17, 1024) 0           activation_212[0][0]             \n",
      "                                                                 activation_215[0][0]             \n",
      "                                                                 activation_220[0][0]             \n",
      "                                                                 activation_221[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_226 (Conv2D)             (None, 17, 17, 192)  196608      concatenate_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_227 (BatchN (None, 17, 17, 192)  576         conv2d_226[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_226 (Activation)     (None, 17, 17, 192)  0           batch_normalization_227[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_227 (Conv2D)             (None, 17, 17, 192)  258048      activation_226[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_228 (BatchN (None, 17, 17, 192)  576         conv2d_227[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_227 (Activation)     (None, 17, 17, 192)  0           batch_normalization_228[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_223 (Conv2D)             (None, 17, 17, 192)  196608      concatenate_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_228 (Conv2D)             (None, 17, 17, 224)  301056      activation_227[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_224 (BatchN (None, 17, 17, 192)  576         conv2d_223[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_229 (BatchN (None, 17, 17, 224)  672         conv2d_228[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_223 (Activation)     (None, 17, 17, 192)  0           batch_normalization_224[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_228 (Activation)     (None, 17, 17, 224)  0           batch_normalization_229[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_224 (Conv2D)             (None, 17, 17, 224)  301056      activation_223[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_229 (Conv2D)             (None, 17, 17, 224)  351232      activation_228[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_225 (BatchN (None, 17, 17, 224)  672         conv2d_224[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_230 (BatchN (None, 17, 17, 224)  672         conv2d_229[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_224 (Activation)     (None, 17, 17, 224)  0           batch_normalization_225[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_229 (Activation)     (None, 17, 17, 224)  0           batch_normalization_230[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_21 (AveragePo (None, 17, 17, 1024) 0           concatenate_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_222 (Conv2D)             (None, 17, 17, 384)  393216      concatenate_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_225 (Conv2D)             (None, 17, 17, 256)  401408      activation_224[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_230 (Conv2D)             (None, 17, 17, 256)  401408      activation_229[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_231 (Conv2D)             (None, 17, 17, 128)  131072      average_pooling2d_21[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_223 (BatchN (None, 17, 17, 384)  1152        conv2d_222[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_226 (BatchN (None, 17, 17, 256)  768         conv2d_225[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_231 (BatchN (None, 17, 17, 256)  768         conv2d_230[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_232 (BatchN (None, 17, 17, 128)  384         conv2d_231[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_222 (Activation)     (None, 17, 17, 384)  0           batch_normalization_223[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_225 (Activation)     (None, 17, 17, 256)  0           batch_normalization_226[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_230 (Activation)     (None, 17, 17, 256)  0           batch_normalization_231[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_231 (Activation)     (None, 17, 17, 128)  0           batch_normalization_232[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_36 (Concatenate)    (None, 17, 17, 1024) 0           activation_222[0][0]             \n",
      "                                                                 activation_225[0][0]             \n",
      "                                                                 activation_230[0][0]             \n",
      "                                                                 activation_231[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_236 (Conv2D)             (None, 17, 17, 192)  196608      concatenate_36[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_237 (BatchN (None, 17, 17, 192)  576         conv2d_236[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_236 (Activation)     (None, 17, 17, 192)  0           batch_normalization_237[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_237 (Conv2D)             (None, 17, 17, 192)  258048      activation_236[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_238 (BatchN (None, 17, 17, 192)  576         conv2d_237[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_237 (Activation)     (None, 17, 17, 192)  0           batch_normalization_238[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_233 (Conv2D)             (None, 17, 17, 192)  196608      concatenate_36[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_238 (Conv2D)             (None, 17, 17, 224)  301056      activation_237[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_234 (BatchN (None, 17, 17, 192)  576         conv2d_233[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_239 (BatchN (None, 17, 17, 224)  672         conv2d_238[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_233 (Activation)     (None, 17, 17, 192)  0           batch_normalization_234[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_238 (Activation)     (None, 17, 17, 224)  0           batch_normalization_239[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_234 (Conv2D)             (None, 17, 17, 224)  301056      activation_233[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_239 (Conv2D)             (None, 17, 17, 224)  351232      activation_238[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_235 (BatchN (None, 17, 17, 224)  672         conv2d_234[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_240 (BatchN (None, 17, 17, 224)  672         conv2d_239[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_234 (Activation)     (None, 17, 17, 224)  0           batch_normalization_235[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_239 (Activation)     (None, 17, 17, 224)  0           batch_normalization_240[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_22 (AveragePo (None, 17, 17, 1024) 0           concatenate_36[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_232 (Conv2D)             (None, 17, 17, 384)  393216      concatenate_36[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_235 (Conv2D)             (None, 17, 17, 256)  401408      activation_234[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_240 (Conv2D)             (None, 17, 17, 256)  401408      activation_239[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_241 (Conv2D)             (None, 17, 17, 128)  131072      average_pooling2d_22[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_233 (BatchN (None, 17, 17, 384)  1152        conv2d_232[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_236 (BatchN (None, 17, 17, 256)  768         conv2d_235[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_241 (BatchN (None, 17, 17, 256)  768         conv2d_240[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_242 (BatchN (None, 17, 17, 128)  384         conv2d_241[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_232 (Activation)     (None, 17, 17, 384)  0           batch_normalization_233[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_235 (Activation)     (None, 17, 17, 256)  0           batch_normalization_236[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_240 (Activation)     (None, 17, 17, 256)  0           batch_normalization_241[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_241 (Activation)     (None, 17, 17, 128)  0           batch_normalization_242[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_37 (Concatenate)    (None, 17, 17, 1024) 0           activation_232[0][0]             \n",
      "                                                                 activation_235[0][0]             \n",
      "                                                                 activation_240[0][0]             \n",
      "                                                                 activation_241[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_246 (Conv2D)             (None, 17, 17, 192)  196608      concatenate_37[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_247 (BatchN (None, 17, 17, 192)  576         conv2d_246[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_246 (Activation)     (None, 17, 17, 192)  0           batch_normalization_247[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_247 (Conv2D)             (None, 17, 17, 192)  258048      activation_246[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_248 (BatchN (None, 17, 17, 192)  576         conv2d_247[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_247 (Activation)     (None, 17, 17, 192)  0           batch_normalization_248[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_243 (Conv2D)             (None, 17, 17, 192)  196608      concatenate_37[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_248 (Conv2D)             (None, 17, 17, 224)  301056      activation_247[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_244 (BatchN (None, 17, 17, 192)  576         conv2d_243[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_249 (BatchN (None, 17, 17, 224)  672         conv2d_248[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_243 (Activation)     (None, 17, 17, 192)  0           batch_normalization_244[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_248 (Activation)     (None, 17, 17, 224)  0           batch_normalization_249[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_244 (Conv2D)             (None, 17, 17, 224)  301056      activation_243[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_249 (Conv2D)             (None, 17, 17, 224)  351232      activation_248[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_245 (BatchN (None, 17, 17, 224)  672         conv2d_244[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_250 (BatchN (None, 17, 17, 224)  672         conv2d_249[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_244 (Activation)     (None, 17, 17, 224)  0           batch_normalization_245[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_249 (Activation)     (None, 17, 17, 224)  0           batch_normalization_250[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_23 (AveragePo (None, 17, 17, 1024) 0           concatenate_37[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_242 (Conv2D)             (None, 17, 17, 384)  393216      concatenate_37[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_245 (Conv2D)             (None, 17, 17, 256)  401408      activation_244[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_250 (Conv2D)             (None, 17, 17, 256)  401408      activation_249[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_251 (Conv2D)             (None, 17, 17, 128)  131072      average_pooling2d_23[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_243 (BatchN (None, 17, 17, 384)  1152        conv2d_242[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_246 (BatchN (None, 17, 17, 256)  768         conv2d_245[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_251 (BatchN (None, 17, 17, 256)  768         conv2d_250[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_252 (BatchN (None, 17, 17, 128)  384         conv2d_251[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_242 (Activation)     (None, 17, 17, 384)  0           batch_normalization_243[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_245 (Activation)     (None, 17, 17, 256)  0           batch_normalization_246[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_250 (Activation)     (None, 17, 17, 256)  0           batch_normalization_251[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_251 (Activation)     (None, 17, 17, 128)  0           batch_normalization_252[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_38 (Concatenate)    (None, 17, 17, 1024) 0           activation_242[0][0]             \n",
      "                                                                 activation_245[0][0]             \n",
      "                                                                 activation_250[0][0]             \n",
      "                                                                 activation_251[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_256 (Conv2D)             (None, 17, 17, 192)  196608      concatenate_38[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_257 (BatchN (None, 17, 17, 192)  576         conv2d_256[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_256 (Activation)     (None, 17, 17, 192)  0           batch_normalization_257[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_257 (Conv2D)             (None, 17, 17, 192)  258048      activation_256[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_258 (BatchN (None, 17, 17, 192)  576         conv2d_257[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_257 (Activation)     (None, 17, 17, 192)  0           batch_normalization_258[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_253 (Conv2D)             (None, 17, 17, 192)  196608      concatenate_38[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_258 (Conv2D)             (None, 17, 17, 224)  301056      activation_257[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_254 (BatchN (None, 17, 17, 192)  576         conv2d_253[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_259 (BatchN (None, 17, 17, 224)  672         conv2d_258[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_253 (Activation)     (None, 17, 17, 192)  0           batch_normalization_254[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_258 (Activation)     (None, 17, 17, 224)  0           batch_normalization_259[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_254 (Conv2D)             (None, 17, 17, 224)  301056      activation_253[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_259 (Conv2D)             (None, 17, 17, 224)  351232      activation_258[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_255 (BatchN (None, 17, 17, 224)  672         conv2d_254[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_260 (BatchN (None, 17, 17, 224)  672         conv2d_259[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_254 (Activation)     (None, 17, 17, 224)  0           batch_normalization_255[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_259 (Activation)     (None, 17, 17, 224)  0           batch_normalization_260[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_24 (AveragePo (None, 17, 17, 1024) 0           concatenate_38[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_252 (Conv2D)             (None, 17, 17, 384)  393216      concatenate_38[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_255 (Conv2D)             (None, 17, 17, 256)  401408      activation_254[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_260 (Conv2D)             (None, 17, 17, 256)  401408      activation_259[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_261 (Conv2D)             (None, 17, 17, 128)  131072      average_pooling2d_24[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_253 (BatchN (None, 17, 17, 384)  1152        conv2d_252[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_256 (BatchN (None, 17, 17, 256)  768         conv2d_255[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_261 (BatchN (None, 17, 17, 256)  768         conv2d_260[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_262 (BatchN (None, 17, 17, 128)  384         conv2d_261[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_252 (Activation)     (None, 17, 17, 384)  0           batch_normalization_253[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_255 (Activation)     (None, 17, 17, 256)  0           batch_normalization_256[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_260 (Activation)     (None, 17, 17, 256)  0           batch_normalization_261[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_261 (Activation)     (None, 17, 17, 128)  0           batch_normalization_262[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_39 (Concatenate)    (None, 17, 17, 1024) 0           activation_252[0][0]             \n",
      "                                                                 activation_255[0][0]             \n",
      "                                                                 activation_260[0][0]             \n",
      "                                                                 activation_261[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_264 (Conv2D)             (None, 17, 17, 256)  262144      concatenate_39[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_265 (BatchN (None, 17, 17, 256)  768         conv2d_264[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_264 (Activation)     (None, 17, 17, 256)  0           batch_normalization_265[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_265 (Conv2D)             (None, 17, 17, 256)  458752      activation_264[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_266 (BatchN (None, 17, 17, 256)  768         conv2d_265[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_265 (Activation)     (None, 17, 17, 256)  0           batch_normalization_266[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_262 (Conv2D)             (None, 17, 17, 192)  196608      concatenate_39[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_266 (Conv2D)             (None, 17, 17, 320)  573440      activation_265[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_263 (BatchN (None, 17, 17, 192)  576         conv2d_262[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_267 (BatchN (None, 17, 17, 320)  960         conv2d_266[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_262 (Activation)     (None, 17, 17, 192)  0           batch_normalization_263[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_266 (Activation)     (None, 17, 17, 320)  0           batch_normalization_267[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_263 (Conv2D)             (None, 8, 8, 192)    331776      activation_262[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_267 (Conv2D)             (None, 8, 8, 320)    921600      activation_266[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_264 (BatchN (None, 8, 8, 192)    576         conv2d_263[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_268 (BatchN (None, 8, 8, 320)    960         conv2d_267[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_263 (Activation)     (None, 8, 8, 192)    0           batch_normalization_264[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_267 (Activation)     (None, 8, 8, 320)    0           batch_normalization_268[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 8, 8, 1024)   0           concatenate_39[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_40 (Concatenate)    (None, 8, 8, 1536)   0           activation_263[0][0]             \n",
      "                                                                 activation_267[0][0]             \n",
      "                                                                 max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_272 (Conv2D)             (None, 8, 8, 384)    589824      concatenate_40[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_273 (BatchN (None, 8, 8, 384)    1152        conv2d_272[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_272 (Activation)     (None, 8, 8, 384)    0           batch_normalization_273[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_273 (Conv2D)             (None, 8, 8, 448)    516096      activation_272[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_274 (BatchN (None, 8, 8, 448)    1344        conv2d_273[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_273 (Activation)     (None, 8, 8, 448)    0           batch_normalization_274[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_269 (Conv2D)             (None, 8, 8, 384)    589824      concatenate_40[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_274 (Conv2D)             (None, 8, 8, 512)    688128      activation_273[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_270 (BatchN (None, 8, 8, 384)    1152        conv2d_269[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_275 (BatchN (None, 8, 8, 512)    1536        conv2d_274[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_269 (Activation)     (None, 8, 8, 384)    0           batch_normalization_270[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_274 (Activation)     (None, 8, 8, 512)    0           batch_normalization_275[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_270 (Conv2D)             (None, 8, 8, 256)    294912      activation_269[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_271 (Conv2D)             (None, 8, 8, 256)    294912      activation_269[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_275 (Conv2D)             (None, 8, 8, 256)    393216      activation_274[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_276 (Conv2D)             (None, 8, 8, 256)    393216      activation_274[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_25 (AveragePo (None, 8, 8, 1536)   0           concatenate_40[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_268 (Conv2D)             (None, 8, 8, 256)    393216      concatenate_40[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_271 (BatchN (None, 8, 8, 256)    768         conv2d_270[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_272 (BatchN (None, 8, 8, 256)    768         conv2d_271[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_276 (BatchN (None, 8, 8, 256)    768         conv2d_275[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_277 (BatchN (None, 8, 8, 256)    768         conv2d_276[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_277 (Conv2D)             (None, 8, 8, 256)    393216      average_pooling2d_25[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_269 (BatchN (None, 8, 8, 256)    768         conv2d_268[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_270 (Activation)     (None, 8, 8, 256)    0           batch_normalization_271[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_271 (Activation)     (None, 8, 8, 256)    0           batch_normalization_272[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_275 (Activation)     (None, 8, 8, 256)    0           batch_normalization_276[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_276 (Activation)     (None, 8, 8, 256)    0           batch_normalization_277[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_278 (BatchN (None, 8, 8, 256)    768         conv2d_277[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_268 (Activation)     (None, 8, 8, 256)    0           batch_normalization_269[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_41 (Concatenate)    (None, 8, 8, 512)    0           activation_270[0][0]             \n",
      "                                                                 activation_271[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_42 (Concatenate)    (None, 8, 8, 512)    0           activation_275[0][0]             \n",
      "                                                                 activation_276[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_277 (Activation)     (None, 8, 8, 256)    0           batch_normalization_278[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_43 (Concatenate)    (None, 8, 8, 1536)   0           activation_268[0][0]             \n",
      "                                                                 concatenate_41[0][0]             \n",
      "                                                                 concatenate_42[0][0]             \n",
      "                                                                 activation_277[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_282 (Conv2D)             (None, 8, 8, 384)    589824      concatenate_43[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_283 (BatchN (None, 8, 8, 384)    1152        conv2d_282[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_282 (Activation)     (None, 8, 8, 384)    0           batch_normalization_283[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_283 (Conv2D)             (None, 8, 8, 448)    516096      activation_282[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_284 (BatchN (None, 8, 8, 448)    1344        conv2d_283[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_283 (Activation)     (None, 8, 8, 448)    0           batch_normalization_284[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_279 (Conv2D)             (None, 8, 8, 384)    589824      concatenate_43[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_284 (Conv2D)             (None, 8, 8, 512)    688128      activation_283[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_280 (BatchN (None, 8, 8, 384)    1152        conv2d_279[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_285 (BatchN (None, 8, 8, 512)    1536        conv2d_284[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_279 (Activation)     (None, 8, 8, 384)    0           batch_normalization_280[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_284 (Activation)     (None, 8, 8, 512)    0           batch_normalization_285[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_280 (Conv2D)             (None, 8, 8, 256)    294912      activation_279[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_281 (Conv2D)             (None, 8, 8, 256)    294912      activation_279[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_285 (Conv2D)             (None, 8, 8, 256)    393216      activation_284[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_286 (Conv2D)             (None, 8, 8, 256)    393216      activation_284[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_26 (AveragePo (None, 8, 8, 1536)   0           concatenate_43[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_278 (Conv2D)             (None, 8, 8, 256)    393216      concatenate_43[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_281 (BatchN (None, 8, 8, 256)    768         conv2d_280[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_282 (BatchN (None, 8, 8, 256)    768         conv2d_281[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_286 (BatchN (None, 8, 8, 256)    768         conv2d_285[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_287 (BatchN (None, 8, 8, 256)    768         conv2d_286[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_287 (Conv2D)             (None, 8, 8, 256)    393216      average_pooling2d_26[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_279 (BatchN (None, 8, 8, 256)    768         conv2d_278[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_280 (Activation)     (None, 8, 8, 256)    0           batch_normalization_281[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_281 (Activation)     (None, 8, 8, 256)    0           batch_normalization_282[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_285 (Activation)     (None, 8, 8, 256)    0           batch_normalization_286[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_286 (Activation)     (None, 8, 8, 256)    0           batch_normalization_287[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_288 (BatchN (None, 8, 8, 256)    768         conv2d_287[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_278 (Activation)     (None, 8, 8, 256)    0           batch_normalization_279[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_44 (Concatenate)    (None, 8, 8, 512)    0           activation_280[0][0]             \n",
      "                                                                 activation_281[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_45 (Concatenate)    (None, 8, 8, 512)    0           activation_285[0][0]             \n",
      "                                                                 activation_286[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_287 (Activation)     (None, 8, 8, 256)    0           batch_normalization_288[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_46 (Concatenate)    (None, 8, 8, 1536)   0           activation_278[0][0]             \n",
      "                                                                 concatenate_44[0][0]             \n",
      "                                                                 concatenate_45[0][0]             \n",
      "                                                                 activation_287[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_292 (Conv2D)             (None, 8, 8, 384)    589824      concatenate_46[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_293 (BatchN (None, 8, 8, 384)    1152        conv2d_292[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_292 (Activation)     (None, 8, 8, 384)    0           batch_normalization_293[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_293 (Conv2D)             (None, 8, 8, 448)    516096      activation_292[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_294 (BatchN (None, 8, 8, 448)    1344        conv2d_293[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_293 (Activation)     (None, 8, 8, 448)    0           batch_normalization_294[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_289 (Conv2D)             (None, 8, 8, 384)    589824      concatenate_46[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_294 (Conv2D)             (None, 8, 8, 512)    688128      activation_293[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_290 (BatchN (None, 8, 8, 384)    1152        conv2d_289[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_295 (BatchN (None, 8, 8, 512)    1536        conv2d_294[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_289 (Activation)     (None, 8, 8, 384)    0           batch_normalization_290[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_294 (Activation)     (None, 8, 8, 512)    0           batch_normalization_295[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_290 (Conv2D)             (None, 8, 8, 256)    294912      activation_289[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_291 (Conv2D)             (None, 8, 8, 256)    294912      activation_289[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_295 (Conv2D)             (None, 8, 8, 256)    393216      activation_294[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_296 (Conv2D)             (None, 8, 8, 256)    393216      activation_294[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_27 (AveragePo (None, 8, 8, 1536)   0           concatenate_46[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_288 (Conv2D)             (None, 8, 8, 256)    393216      concatenate_46[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_291 (BatchN (None, 8, 8, 256)    768         conv2d_290[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_292 (BatchN (None, 8, 8, 256)    768         conv2d_291[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_296 (BatchN (None, 8, 8, 256)    768         conv2d_295[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_297 (BatchN (None, 8, 8, 256)    768         conv2d_296[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_297 (Conv2D)             (None, 8, 8, 256)    393216      average_pooling2d_27[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_289 (BatchN (None, 8, 8, 256)    768         conv2d_288[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_290 (Activation)     (None, 8, 8, 256)    0           batch_normalization_291[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_291 (Activation)     (None, 8, 8, 256)    0           batch_normalization_292[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_295 (Activation)     (None, 8, 8, 256)    0           batch_normalization_296[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_296 (Activation)     (None, 8, 8, 256)    0           batch_normalization_297[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_298 (BatchN (None, 8, 8, 256)    768         conv2d_297[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_288 (Activation)     (None, 8, 8, 256)    0           batch_normalization_289[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_47 (Concatenate)    (None, 8, 8, 512)    0           activation_290[0][0]             \n",
      "                                                                 activation_291[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_48 (Concatenate)    (None, 8, 8, 512)    0           activation_295[0][0]             \n",
      "                                                                 activation_296[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_297 (Activation)     (None, 8, 8, 256)    0           batch_normalization_298[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_49 (Concatenate)    (None, 8, 8, 1536)   0           activation_288[0][0]             \n",
      "                                                                 concatenate_47[0][0]             \n",
      "                                                                 concatenate_48[0][0]             \n",
      "                                                                 activation_297[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 1536)         0           concatenate_49[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_299 (BatchN (None, 1536)         6144        global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 512)          786944      batch_normalization_299[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 12)           6156        dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 41,973,644\n",
      "Trainable params: 796,172\n",
      "Non-trainable params: 41,177,472\n",
      "__________________________________________________________________________________________________\n",
      " 2/13 [===>..........................] - ETA: 0sWARNING:tensorflow:Callbacks method `on_predict_batch_end` is slow compared to the batch time (batch time: 0.0316s vs `on_predict_batch_end` time: 0.1162s). Check your callbacks.\n",
      "13/13 [==============================] - 2s 140ms/step\n",
      "Loss: 0.8241333365440369\n",
      "Accuracy: 0.07851749658584595\n",
      "Execution Time: 27.938\n",
      "Confusion Matrix: \n",
      " [[ 1 20  0  0  0  0  0  0 14  0  3  1]\n",
      " [ 2  5  0  0  0  0  0  0 18  0  5  2]\n",
      " [ 3 23  0  0  0  0  0  0  9  0  1  0]\n",
      " [ 0 20  0  0  0  0  0  0 10  0  3  6]\n",
      " [ 2 15  0  0  0  0  0  0 20  0  0  1]\n",
      " [ 0 17  0  0  0  0  0  0  9  0  3  0]\n",
      " [ 0 22  0  0  0  0  0  0  8  0  2  0]\n",
      " [ 0 12  0  0  0  0  0  0  1  0 15  0]\n",
      " [ 4  9  0  0  0  0  0  0 16  1  1  0]\n",
      " [ 2  6  0  0  0  0  0  0 19  1  1  1]\n",
      " [ 3  6  0  0  0  0  0  0 23  0  2  0]\n",
      " [ 2 19  0  0  0  0  0  0  9  0  3  0]]\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_7849cfc4-d311-4ec6-87b8-c7ad96e19a99\", \"cm_inception_v4.pdf\", 16592)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "## Star Time\n",
    "checkpoint_time = get_time()\n",
    "\n",
    "## Definitions\n",
    "NUM_CLASSES = 12\n",
    "IMG_ROWS = 299\n",
    "IMG_COLS = 299\n",
    "EPOCHS = 64\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "## Loading Inital Data\n",
    "(x_train, y_train), (x_test, y_test) = load_dataset(TRAIN_FILE, TEST_FILE, resize=True, convert=True, size=(IMG_ROWS, IMG_COLS))\n",
    "\n",
    "## Normalize images\n",
    "x_train = normalize_images(x_train)\n",
    "x_test = normalize_images(x_test)\n",
    "\n",
    "## Generating Labels for Confusion Matrix\n",
    "labels = generate_labels(x_test, y_test)\n",
    "\n",
    "## Convert class vectros to binary class matrices\n",
    "y_train = convert_vector(y_train, NUM_CLASSES)\n",
    "y_test = convert_vector(y_test, NUM_CLASSES)\n",
    "\n",
    "model = get_model(num_classes=NUM_CLASSES)\n",
    "\n",
    "model.compile(loss='mse', optimizer=keras.optimizers.Adam(learning_rate=0.00005), metrics=['mse', 'acc'])\n",
    "\n",
    "## Trainning model\n",
    "# history = fit_model(model, x_train, y_train, x_test, y_test, epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=0)\n",
    "\n",
    "predictions = model.predict(x_test, verbose=1, batch_size=BATCH_SIZE)\n",
    "# print(predictions)\n",
    "\n",
    "## Getting Score\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "## Loss\n",
    "print('Loss:', score[0])\n",
    "\n",
    "## Accuracy\n",
    "print('Accuracy:', score[1])\n",
    "\n",
    "## Execution Time\n",
    "print(f'Execution Time: {get_time_diff(checkpoint_time)}')\n",
    "\n",
    "## Confusion Matrix\n",
    "cm = get_confusion_matrix(model, x_test, labels)\n",
    "print(f'Confusion Matrix: \\n', cm)\n",
    "plot_confusion_matrix(cm, 'cm_inception_v4.pdf')\n",
    "#\n",
    "### Graphs\n",
    "#plot_graphs(history, 'history_vgg16.pdf')\n",
    "#\n",
    "print('DONE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZG3KmqRk1BJd"
   },
   "source": [
    "## JUNTANDO OS DADOS GERADOS COM OS INICIAIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "y-aetoRU1BJf",
    "outputId": "18b57d10-01cc-47b7-cf12-9c0f05d4584b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JUNTANDO OS DADOS GERADOS COM OS INICIAIS - DONE\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "TRAIN_AUG_FILE = './ml_lab3/train-aug.txt'\n",
    "TRAIN_FINAL = './ml_lab3/train-final.txt'\n",
    "\n",
    "def mergeTrainFiles():\n",
    "  filenames = [TRAIN_FILE, TRAIN_AUG_FILE]\n",
    "  with open(TRAIN_FINAL, 'w') as outfile:\n",
    "      for fname in filenames:\n",
    "          with open(fname) as infile:\n",
    "              for line in infile:\n",
    "                  outfile.write(line)\n",
    "\n",
    "mergeTrainFiles()\n",
    "\n",
    "print('JUNTANDO OS DADOS GERADOS COM OS INICIAIS - DONE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y8WsMCMygAJN"
   },
   "source": [
    "## EXTRAINDO AS CARACTERÍSTICAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e4u4qgcsezgq"
   },
   "source": [
    "## CRIANDO OS DIRETÓRIOS E ARQUIVOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DkzblMPziBLg"
   },
   "outputs": [],
   "source": [
    "!mkdir ./ml_lab3/svm\n",
    "!touch ./ml_lab3/svm/test.svm\n",
    "!touch ./ml_lab3/svm/train.svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HPKqNYryeRpe"
   },
   "outputs": [],
   "source": [
    "## Star Time\n",
    "checkpoint_time = get_time()\n",
    "\n",
    "INPUT_FILE_TEST = \"./ml_lab3/test.txt\"\n",
    "OUTPUT_FILE_TEST = \"./ml_lab3/svm/test.svm\"\n",
    "INPUT_FILE_TRAIN = TRAIN_FINAL\n",
    "OUTPUT_FILE_TRAIN = \"./ml_lab3/svm/train.svm\"\n",
    "IMG_ROWS = 100\n",
    "IMG_COLS = 100\n",
    "DIR_DATASET = \"./ml_lab3/\"\n",
    "\n",
    "model = get_model()\n",
    "\n",
    "# Train\n",
    "extract_features(model, INPUT_FILE_TRAIN, OUTPUT_FILE_TRAIN, IMG_ROWS, IMG_COLS, DIR_DATASET)\n",
    "\n",
    "# Test\n",
    "extract_features(model, INPUT_FILE_TEST, OUTPUT_FILE_TEST, IMG_ROWS, IMG_COLS, DIR_DATASET)\n",
    "\n",
    "## Execution Time\n",
    "print(f'Execution Time: {get_time_diff(checkpoint_time)}')\n",
    "\n",
    "print('EXTRAINDO AS CARACTERÍSTICAS - DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pv6MqVuRBtDb"
   },
   "outputs": [],
   "source": [
    "!zip -r /content/ml_lab3.zip /content/ml_lab3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "hmeZl2X8POu8",
    "outputId": "cc0d3ca8-d637-4a75-ef65-2ea571126763"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit:1 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
      "Hit:2 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease    \u001b[0m\n",
      "Hit:3 http://archive.ubuntu.com/ubuntu bionic InRelease                        \u001b[0m\u001b[33m\n",
      "Hit:4 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease       \u001b[0m\n",
      "Hit:5 http://archive.ubuntu.com/ubuntu bionic-updates InRelease                \u001b[0m\n",
      "Hit:6 http://archive.ubuntu.com/ubuntu bionic-backports InRelease              \u001b[0m\n",
      "Hit:7 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease\n",
      "Ign:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
      "Ign:9 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
      "Hit:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
      "Hit:11 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "72 packages can be upgraded. Run 'apt list --upgradable' to see them.\n"
     ]
    }
   ],
   "source": [
    "!apt update\n",
    "!apt install magic-wormhole\n",
    "!wormhole send /content/ml_lab3.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7U0alCIkWmKo"
   },
   "outputs": [],
   "source": [
    "!cat /content/ml_lab3/svm.zip.part* > /content/ml_lab3/svm.zip\n",
    "!unzip -d /content/ml_lab3 /content/ml_lab3/svm.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lgxz2T6-ZEz6"
   },
   "source": [
    "#CPU INFO for threads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 955
    },
    "colab_type": "code",
    "id": "vbvV4oomZDwB",
    "outputId": "bc3fda1d-2370-459c-9e83-8a0d0ad28d2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processor\t: 0\n",
      "vendor_id\t: GenuineIntel\n",
      "cpu family\t: 6\n",
      "model\t\t: 63\n",
      "model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n",
      "stepping\t: 0\n",
      "microcode\t: 0x1\n",
      "cpu MHz\t\t: 2300.000\n",
      "cache size\t: 46080 KB\n",
      "physical id\t: 0\n",
      "siblings\t: 2\n",
      "core id\t\t: 0\n",
      "cpu cores\t: 1\n",
      "apicid\t\t: 0\n",
      "initial apicid\t: 0\n",
      "fpu\t\t: yes\n",
      "fpu_exception\t: yes\n",
      "cpuid level\t: 13\n",
      "wp\t\t: yes\n",
      "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n",
      "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs\n",
      "bogomips\t: 4600.00\n",
      "clflush size\t: 64\n",
      "cache_alignment\t: 64\n",
      "address sizes\t: 46 bits physical, 48 bits virtual\n",
      "power management:\n",
      "\n",
      "processor\t: 1\n",
      "vendor_id\t: GenuineIntel\n",
      "cpu family\t: 6\n",
      "model\t\t: 63\n",
      "model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n",
      "stepping\t: 0\n",
      "microcode\t: 0x1\n",
      "cpu MHz\t\t: 2300.000\n",
      "cache size\t: 46080 KB\n",
      "physical id\t: 0\n",
      "siblings\t: 2\n",
      "core id\t\t: 0\n",
      "cpu cores\t: 1\n",
      "apicid\t\t: 1\n",
      "initial apicid\t: 1\n",
      "fpu\t\t: yes\n",
      "fpu_exception\t: yes\n",
      "cpuid level\t: 13\n",
      "wp\t\t: yes\n",
      "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n",
      "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs\n",
      "bogomips\t: 4600.00\n",
      "clflush size\t: 64\n",
      "cache_alignment\t: 64\n",
      "address sizes\t: 46 bits physical, 48 bits virtual\n",
      "power management:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!cat /proc/cpuinfo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7ujYfRQtXaYv"
   },
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YwpgUkIdXI6C"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4ENxIC7TXdZN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of  10 | elapsed:   19.1s remaining:   12.8s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-a0b4d98f22f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# svm_model = GridSearchCV(SVC(), params_grid, cv=5, verbose=1, n_jobs=-1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0msvm_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_grid_one\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0msvm_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;31m## Execution Time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Execution Time: {get_time_diff(checkpoint_time)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ML/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ML/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ML/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1188\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ML/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    706\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[1;32m    709\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ML/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1042\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1043\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ML/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ML/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    432\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## Star Time\n",
    "checkpoint_time = get_time()\n",
    "\n",
    "INPUT_TRAIN = \"../ml_lab3/svm/train.svm\"\n",
    "INPUT_TEST = \"../ml_lab3/svm/test.svm\"\n",
    "\n",
    "x_train, y_train = load_svmlight_file(INPUT_TRAIN)\n",
    "x_test, y_test = load_svmlight_file(INPUT_TEST)\n",
    "\n",
    "x_train = x_train.toarray()\n",
    "x_test = x_test.toarray()\n",
    "\n",
    "#Libraries to Build Ensemble Model : Random Forest Classifier \n",
    "# Create the parameter grid based on the results of random search \n",
    "params_grid = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "params_grid_one = [{'kernel': ['rbf'], 'gamma': [1e-3],\n",
    "                     'C': [1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1000]}]\n",
    "\n",
    "# Performing CV to tune parameters for best SVM fit \n",
    "# svm_model = GridSearchCV(SVC(), params_grid, cv=5, verbose=1, n_jobs=-1)\n",
    "svm_model = GridSearchCV(SVC(), params_grid_one, cv=5, verbose=1, n_jobs=-1)\n",
    "svm_model.fit(x_train, y_train)\n",
    "## Execution Time\n",
    "print(f'Execution Time: {get_time_diff(checkpoint_time)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vj9hxuBpyAsF"
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "TRAIN_AUG_FILE = './ml_lab3/train-aug.txt'\n",
    "TRAIN_FINAL = './ml_lab3/train-final.txt'\n",
    "\n",
    "def mergeTrainFiles():\n",
    "  filenames = [TRAIN_FILE, TRAIN_AUG_FILE]\n",
    "  with open(TRAIN_FINAL, 'w') as outfile:\n",
    "      for fname in filenames:\n",
    "          with open(fname) as infile:\n",
    "              for line in infile:\n",
    "                  outfile.write(line)\n",
    "\n",
    "mergeTrainFiles()\n",
    "\n",
    "print('Preparando o arquivo de treino - DONE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SSB4kWlAx9BJ"
   },
   "source": [
    "## Preparação para testes com dados augumentados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3oLR5byxN9Dj"
   },
   "outputs": [],
   "source": [
    "## Definitions\n",
    "NUM_CLASSES = 12\n",
    "BATCH_SIZE = 64\n",
    "NUM_CLASSES = 12\n",
    "IMG_ROWS = 299\n",
    "IMG_COLS = 299\n",
    "EPOCHS = 12\n",
    "\n",
    "## Loading Initial Data\n",
    "(x_train, y_train), (x_test, y_test) = load_dataset(TRAIN_FINAL, TEST_FILE, resize=True, convert=True, size=(IMG_ROWS, IMG_COLS))\n",
    "\n",
    "# Normalize images\n",
    "x_train = normalize_images(x_train)\n",
    "x_test = normalize_images(x_test)\n",
    "\n",
    "## Generating Labels for Confusion Matrix\n",
    "labels = generate_labels(x_test, y_test)\n",
    "\n",
    "## Convert class vectros to binary class matrices\n",
    "y_train = convert_vector(y_train, NUM_CLASSES)\n",
    "y_test = convert_vector(y_test, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WoqWLVSkAG5W"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "BATCH_SIZE=32\n",
    "SAVED_MODEL_NAME=\"my_model.d5\"\n",
    "# Y_train = df_train.diagnosis.values\n",
    "# print(y_train)\n",
    "# class_weight_ = class_weight.compute_class_weight('balanced',np.unique(y_train),y_train)\n",
    "# print(class_weight_)\n",
    "# ---------------------------------------------- \n",
    "def get_preds_and_labels(model, generator):\n",
    "    \"\"\"\n",
    "    Get predictions and labels from the generator\n",
    "    \"\"\"\n",
    "    preds = []\n",
    "    labels = []\n",
    "    for _ in range(int(np.ceil(generator.samples / BATCH_SIZE))):\n",
    "        x, y = next(generator)\n",
    "        preds.append(model.predict(x))\n",
    "        labels.append(y)\n",
    "    # Flatten list of numpy arrays\n",
    "    return np.concatenate(preds).ravel(), np.concatenate(labels).ravel()\n",
    "# ---------------------------------------------- \n",
    "class Metrics(Callback):\n",
    "    \"\"\"\n",
    "    A custom Keras callback for saving the best model\n",
    "    according to the Quadratic Weighted Kappa (QWK) metric\n",
    "    \"\"\"\n",
    "    def on_train_begin(self, logs={}):\n",
    "        \"\"\"\n",
    "        Initialize list of QWK scores on validation data\n",
    "        \"\"\"\n",
    "        self.val_kappas = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \"\"\"\n",
    "        Gets QWK score on the validation data\n",
    "        \"\"\"\n",
    "        # Get predictions and convert to integers\n",
    "        y_pred, labels = get_preds_and_labels(model, valid_generator)\n",
    "        y_pred = np.rint(y_pred).astype(np.uint8).clip(0, 4)\n",
    "        # We can use sklearns implementation of QWK straight out of the box\n",
    "        # as long as we specify weights as 'quadratic'\n",
    "        _val_kappa = cohen_kappa_score(labels, y_pred, weights='quadratic')\n",
    "        self.val_kappas.append(_val_kappa)\n",
    "        print(f\"val_kappa: {round(_val_kappa, 4)}\")\n",
    "        if _val_kappa == max(self.val_kappas):\n",
    "            print(\"Validation Kappa has improved. Saving model.\")\n",
    "            self.model.save(SAVED_MODEL_NAME)\n",
    "        return\n",
    "# ---------------------------------------------- \n",
    "kappa_metrics = Metrics()\n",
    "#from keras.utils import multi_gpu_model\n",
    "\n",
    "# df_train.id_code=df_train.id_code.apply(lambda x: x+\".png\")\n",
    "# df_train['diagnosis'] = df_train['diagnosis'].astype('str')\n",
    "# \n",
    "# df_test.id_code=df_test.id_code.apply(lambda x: x+\".png\")\n",
    "# \n",
    "# aug = ImageDataGenerator(rescale=1./255, validation_split=0.2, horizontal_flip=True, \n",
    "#                          vertical_flip=True, rotation_range=120, zoom_range=0.1, \n",
    "#                          width_shift_range=0.2, shear_range=0.15, fill_mode='nearest')\n",
    "# \n",
    "# train_generator=aug.flow_from_dataframe(dataframe=df_train, \n",
    "#                                         #directory=\"../input/aptos2019-blindness-detection/train_images/\",\n",
    "#                                         directory=\"../input/train_images/\",\n",
    "#                                         x_col=\"id_code\", y_col=\"diagnosis\",\n",
    "#                                         batch_size=BATCH_SIZE, class_mode=\"categorical\", target_size=(299, 299),\n",
    "#                                         #preprocessing_function=circle_crop,\n",
    "#                                         subset='training', shaffle=False, seed=SEED)\n",
    "# \n",
    "# valid_generator=aug.flow_from_dataframe(dataframe=df_train, \n",
    "#                                         #directory=\"../input/aptos2019-blindness-detection/train_images/\",\n",
    "#                                         directory=\"../input/train_images/\",\n",
    "#                                         x_col=\"id_code\", y_col=\"diagnosis\",\n",
    "#                                         batch_size=BATCH_SIZE, class_mode=\"categorical\", target_size=(299, 299),\n",
    "#                                         #preprocessing_function=circle_crop,\n",
    "#                                         subset='validation', shaffle=False, seed=SEED)\n",
    "# \n",
    "# model.compile(loss='mse', optimizer=RAdam(lr=0.00005, name=None), metrics=['mse', 'acc'])\n",
    "model.compile(loss='mse', optimizer=keras.optimizers.Adam(learning_rate=0.00005), metrics=['mse', 'acc'])\n",
    "# (x=x_train, y=y_train, epochs=epochs, batch_size=batch_size, validation_data=(x_test, y_test), verbose=verbose)\n",
    "## Star Time\n",
    "checkpoint_time = get_time()\n",
    "history = model.fit(x=x_train, y=y_train, epochs=40, steps_per_epoch=100, validation_data=(x_test, y_test), callbacks=[early_stop, reduce_lr], verbose=1)\n",
    "# H = model.fit(x=x_train, y=y_train, epochs=40, steps_per_epoch=100, validation_data=(x_test, y_test), callbacks=[kappa_metrics, early_stop, reduce_lr], verbose=1)\n",
    "# \n",
    "# H = model.fit_generator(generator=train_generator, validation_steps=50, \n",
    "#                          validation_data=valid_generator,\n",
    "#                          callbacks=[kappa_metrics, early_stop, reduce_lr],\n",
    "#                          steps_per_epoch=100, \n",
    "#                          epochs=40, \n",
    "#                          verbose=1)\n",
    "\n",
    "#                         class_weight = class_weight_)\n",
    "# -------------------------------------------\n",
    "#tlog(\"done\")\n",
    "\n",
    "## Getting Score\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "## Loss\n",
    "print('Loss:', score[0])\n",
    "\n",
    "## Accuracy\n",
    "print('Accuracy:', score[1])\n",
    "\n",
    "## Execution Time\n",
    "print(f'Execution Time: {get_time_diff(checkpoint_time)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KcC5nNiExmTM"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q7FuSWojxmTP"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yuvSre_1buXw"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.title(\"Learning curve\")\n",
    "plt.plot(H.history[\"loss\"], label=\"loss\")\n",
    "plt.plot(H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot( np.argmin(H.history[\"val_loss\"]), np.min(H.history[\"val_loss\"]), marker=\"x\", color=\"r\", label=\"best model\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"log_loss\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CDRDecUAbuXz"
   },
   "outputs": [],
   "source": [
    "accu = H.history['acc']\n",
    "val_acc = H.history['val_acc']\n",
    "\n",
    "plt.plot(accu,label=\"Accuracy\")\n",
    "plt.plot(val_acc)\n",
    "plt.plot(kappa_metrics.val_kappas)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend(['Acc','val_acc','kappa'])\n",
    "plt.plot( np.argmax(H.history[\"val_acc\"]), np.max(H.history[\"val_acc\"]), marker=\"x\", color=\"r\", label=\"best model\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hUK9h8JpbuX1"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from math import ceil\n",
    "\n",
    "aug_test = ImageDataGenerator(rescale=1./255, validation_split=0.2, zoom_range=0.1,\n",
    "                              horizontal_flip=True, rotation_range=40)\n",
    "\n",
    "test_generator=aug_test.flow_from_dataframe(dataframe=df_test, \n",
    "                                       #directory = \"../input/aptos2019-blindness-detection/test_images/\",\n",
    "                                       directory = \"../input/test_images/\",\n",
    "                                       x_col=\"id_code\",\n",
    "                                       target_size=(299, 299),batch_size=1,shuffle=False, \n",
    "                                       #preprocessing_function=circle_crop,\n",
    "                                       class_mode=None, seed=SEED)\n",
    "# -----------------------------------------------------    \n",
    "model.load_weights(SAVED_MODEL_NAME)\n",
    "\n",
    "preds_tta=[]\n",
    "for i in tqdm(range(20)):\n",
    "    test_generator.reset()\n",
    "    preds = model.predict_generator(generator=test_generator,steps = ceil(df_test.shape[0]))\n",
    "    preds_tta.append(preds)\n",
    "# -----------------------------------------------------\n",
    "# print(preds_tta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QgnL91mlbuX4"
   },
   "outputs": [],
   "source": [
    "final_pred = np.mean(preds_tta, axis=0)\n",
    "y_class = np.argmax(final_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YsvMdIR-buX6"
   },
   "outputs": [],
   "source": [
    "df_submit.diagnosis = y_class\n",
    "df_submit.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nbbtbrUtbuX9"
   },
   "outputs": [],
   "source": [
    "df_submit['diagnosis'].value_counts().plot(kind='bar')\n",
    "plt.title('Test Samples Per Class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yVzCAcPQbuX_"
   },
   "outputs": [],
   "source": [
    "#tlog('Finished. Total time:'+str((timeit.default_timer()-start_time)/3600)+' hours.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "Z6nh25nZMnBx",
    "outputId": "ef6ecbde-7390-4aac-a11e-2a8460940989"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
      "Hit:2 http://archive.ubuntu.com/ubuntu bionic InRelease                        \u001b[0m\n",
      "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]      \u001b[0m\n",
      "Get:4 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
      "Get:5 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease [15.4 kB]m\n",
      "Get:6 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]    \u001b[0m\u001b[33m\n",
      "Get:7 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease [3,626 B]\n",
      "Get:8 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [109 kB]\n",
      "Get:9 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [1,067 kB]\n",
      "Ign:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
      "Get:11 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [892 kB]\n",
      "Get:12 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [43.0 kB]\n",
      "Get:13 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [125 kB]\n",
      "Get:14 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [1,362 kB]\n",
      "Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [1,421 kB]\n",
      "Ign:16 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
      "Hit:17 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
      "Get:18 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release [564 B]\n",
      "Get:19 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release.gpg [833 B]\n",
      "Get:20 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main Sources [1,864 kB]\n",
      "Get:21 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main amd64 Packages [900 kB]\n",
      "Get:22 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ Packages [95.7 kB]\n",
      "Get:24 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Packages [47.5 kB]\n",
      "Fetched 8,220 kB in 2s (3,480 kB/s)\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "72 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following package was automatically installed and is no longer required:\n",
      "  libnvidia-common-440\n",
      "Use 'apt autoremove' to remove it.\n",
      "The following additional packages will be installed:\n",
      "  cython3 geoip-database libgeoip1 python3-asn1crypto python3-attr\n",
      "  python3-autobahn python3-automat python3-cbor python3-cffi-backend\n",
      "  python3-click python3-colorama python3-constantly python3-cryptography\n",
      "  python3-geoip python3-hkdf python3-humanize python3-hyperlink python3-idna\n",
      "  python3-incremental python3-lz4 python3-nacl python3-olefile python3-openssl\n",
      "  python3-pam python3-pil python3-pkg-resources python3-pyasn1\n",
      "  python3-pyasn1-modules python3-qrcode python3-serial\n",
      "  python3-service-identity python3-six python3-snappy python3-spake2\n",
      "  python3-tqdm python3-trie python3-twisted python3-twisted-bin python3-txaio\n",
      "  python3-txtorcon python3-u-msgpack python3-ubjson python3-wsaccel\n",
      "  python3-zope.interface\n",
      "Suggested packages:\n",
      "  cython-doc geoip-bin python-attr-doc python-cryptography-doc\n",
      "  python3-cryptography-vectors python-nacl-doc python-openssl-doc\n",
      "  python3-openssl-dbg python3-pam-dbg python-pil-doc python3-pil-dbg\n",
      "  python3-setuptools python3-wxgtk3.0 | python3-wxgtk python-trie-doc\n",
      "  python3-gtk2 python3-glade2 python3-qt4 python3-wxgtk2.8\n",
      "  python3-twisted-bin-dbg python-txaio-doc tor\n",
      "The following NEW packages will be installed:\n",
      "  cython3 geoip-database libgeoip1 magic-wormhole python3-asn1crypto\n",
      "  python3-attr python3-autobahn python3-automat python3-cbor\n",
      "  python3-cffi-backend python3-click python3-colorama python3-constantly\n",
      "  python3-cryptography python3-geoip python3-hkdf python3-humanize\n",
      "  python3-hyperlink python3-idna python3-incremental python3-lz4 python3-nacl\n",
      "  python3-olefile python3-openssl python3-pam python3-pil\n",
      "  python3-pkg-resources python3-pyasn1 python3-pyasn1-modules python3-qrcode\n",
      "  python3-serial python3-service-identity python3-six python3-snappy\n",
      "  python3-spake2 python3-tqdm python3-trie python3-twisted python3-twisted-bin\n",
      "  python3-txaio python3-txtorcon python3-u-msgpack python3-ubjson\n",
      "  python3-wsaccel python3-zope.interface\n",
      "0 upgraded, 45 newly installed, 0 to remove and 72 not upgraded.\n",
      "Need to get 8,123 kB of archives.\n",
      "After this operation, 40.6 MB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 geoip-database all 20180315-1 [2,090 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgeoip1 amd64 1.6.12-1 [71.8 kB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 cython3 amd64 0.26.1-0.4 [1,925 kB]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-attr all 17.4.0-2 [23.8 kB]\n",
      "Get:5 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-cbor amd64 1.0.0-1 [20.2 kB]\n",
      "Get:6 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-lz4 amd64 0.10.1+dfsg1-0.2 [17.0 kB]\n",
      "Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-cffi-backend amd64 1.11.5-1 [64.6 kB]\n",
      "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-six all 1.11.0-2 [11.4 kB]\n",
      "Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-nacl amd64 1.1.2-1build1 [27.9 kB]\n",
      "Get:10 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-asn1crypto all 0.24.0-1 [72.8 kB]\n",
      "Get:11 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-idna all 2.6-1 [32.5 kB]\n",
      "Get:12 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python3-cryptography amd64 2.1.4-1ubuntu1.3 [221 kB]\n",
      "Get:13 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-openssl all 17.5.0-1ubuntu1 [41.5 kB]\n",
      "Get:14 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python3-pil amd64 5.1.0-1ubuntu0.3 [330 kB]\n",
      "Get:15 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-qrcode all 5.3-1 [23.7 kB]\n",
      "Get:16 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-pyasn1 all 0.4.2-3 [46.8 kB]\n",
      "Get:17 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-pyasn1-modules all 0.2.1-0.2 [32.9 kB]\n",
      "Get:18 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-service-identity all 16.0.0-2 [9,388 B]\n",
      "Get:19 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-snappy amd64 0.5-1.1build2 [11.1 kB]\n",
      "Get:20 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-trie all 0.2+ds-1 [7,158 B]\n",
      "Get:21 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-automat all 0.6.0-1 [25.2 kB]\n",
      "Get:22 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-constantly all 15.1.0-1 [8,030 B]\n",
      "Get:23 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-hyperlink all 17.3.1-2 [27.6 kB]\n",
      "Get:24 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-incremental all 16.10.1-3 [14.5 kB]\n",
      "Get:25 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-pkg-resources all 39.0.1-2 [98.8 kB]\n",
      "Get:26 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-zope.interface amd64 4.3.2-1build2 [82.4 kB]\n",
      "Get:27 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python3-twisted-bin amd64 17.9.0-2ubuntu0.1 [11.4 kB]\n",
      "Get:28 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python3-twisted all 17.9.0-2ubuntu0.1 [1,919 kB]\n",
      "Get:29 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-txaio all 2.8.1-1 [18.3 kB]\n",
      "Get:30 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-u-msgpack all 2.1-1 [7,352 B]\n",
      "Get:31 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-ubjson amd64 0.8.5-2build1 [95.2 kB]\n",
      "Get:32 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-wsaccel amd64 0.6.2-1 [37.5 kB]\n",
      "Get:33 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-autobahn all 17.10.1+dfsg1-2 [158 kB]\n",
      "Get:34 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-colorama all 0.3.7-1 [14.9 kB]\n",
      "Get:35 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-click all 6.7-3 [56.5 kB]\n",
      "Get:36 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-hkdf all 0.0.3-3 [5,494 B]\n",
      "Get:37 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-humanize all 0.5.1-2 [12.5 kB]\n",
      "Get:38 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-spake2 all 0.7-3 [30.8 kB]\n",
      "Get:39 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-tqdm all 4.19.5-1 [60.5 kB]\n",
      "Get:40 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-geoip amd64 1.3.2-1build4 [19.2 kB]\n",
      "Get:41 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-txtorcon all 0.19.3-4 [88.1 kB]\n",
      "Get:42 http://archive.ubuntu.com/ubuntu bionic/universe amd64 magic-wormhole all 0.10.3-1 [152 kB]\n",
      "Get:43 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-olefile all 0.45.1-1 [33.3 kB]\n",
      "Get:44 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-pam amd64 0.4.2-13.2ubuntu4 [9,092 B]\n",
      "Get:45 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-serial all 3.4-2 [56.5 kB]\n",
      "Fetched 8,123 kB in 0s (31.2 MB/s)\n",
      "Extracting templates from packages: 100%\n",
      "Selecting previously unselected package geoip-database.\n",
      "(Reading database ... 144579 files and directories currently installed.)\n",
      "Preparing to unpack .../00-geoip-database_20180315-1_all.deb ...\n",
      "Unpacking geoip-database (20180315-1) ...\n",
      "Selecting previously unselected package libgeoip1:amd64.\n",
      "Preparing to unpack .../01-libgeoip1_1.6.12-1_amd64.deb ...\n",
      "Unpacking libgeoip1:amd64 (1.6.12-1) ...\n",
      "Selecting previously unselected package cython3.\n",
      "Preparing to unpack .../02-cython3_0.26.1-0.4_amd64.deb ...\n",
      "Unpacking cython3 (0.26.1-0.4) ...\n",
      "Selecting previously unselected package python3-attr.\n",
      "Preparing to unpack .../03-python3-attr_17.4.0-2_all.deb ...\n",
      "Unpacking python3-attr (17.4.0-2) ...\n",
      "Selecting previously unselected package python3-cbor.\n",
      "Preparing to unpack .../04-python3-cbor_1.0.0-1_amd64.deb ...\n",
      "Unpacking python3-cbor (1.0.0-1) ...\n",
      "Selecting previously unselected package python3-lz4.\n",
      "Preparing to unpack .../05-python3-lz4_0.10.1+dfsg1-0.2_amd64.deb ...\n",
      "Unpacking python3-lz4 (0.10.1+dfsg1-0.2) ...\n",
      "Selecting previously unselected package python3-cffi-backend.\n",
      "Preparing to unpack .../06-python3-cffi-backend_1.11.5-1_amd64.deb ...\n",
      "Unpacking python3-cffi-backend (1.11.5-1) ...\n",
      "Selecting previously unselected package python3-six.\n",
      "Preparing to unpack .../07-python3-six_1.11.0-2_all.deb ...\n",
      "Unpacking python3-six (1.11.0-2) ...\n",
      "Selecting previously unselected package python3-nacl.\n",
      "Preparing to unpack .../08-python3-nacl_1.1.2-1build1_amd64.deb ...\n",
      "Unpacking python3-nacl (1.1.2-1build1) ...\n",
      "Selecting previously unselected package python3-asn1crypto.\n",
      "Preparing to unpack .../09-python3-asn1crypto_0.24.0-1_all.deb ...\n",
      "Unpacking python3-asn1crypto (0.24.0-1) ...\n",
      "Selecting previously unselected package python3-idna.\n",
      "Preparing to unpack .../10-python3-idna_2.6-1_all.deb ...\n",
      "Unpacking python3-idna (2.6-1) ...\n",
      "Selecting previously unselected package python3-cryptography.\n",
      "Preparing to unpack .../11-python3-cryptography_2.1.4-1ubuntu1.3_amd64.deb ...\n",
      "Unpacking python3-cryptography (2.1.4-1ubuntu1.3) ...\n",
      "Selecting previously unselected package python3-openssl.\n",
      "Preparing to unpack .../12-python3-openssl_17.5.0-1ubuntu1_all.deb ...\n",
      "Unpacking python3-openssl (17.5.0-1ubuntu1) ...\n",
      "Selecting previously unselected package python3-pil:amd64.\n",
      "Preparing to unpack .../13-python3-pil_5.1.0-1ubuntu0.3_amd64.deb ...\n",
      "Unpacking python3-pil:amd64 (5.1.0-1ubuntu0.3) ...\n",
      "Selecting previously unselected package python3-qrcode.\n",
      "Preparing to unpack .../14-python3-qrcode_5.3-1_all.deb ...\n",
      "Unpacking python3-qrcode (5.3-1) ...\n",
      "Selecting previously unselected package python3-pyasn1.\n",
      "Preparing to unpack .../15-python3-pyasn1_0.4.2-3_all.deb ...\n",
      "Unpacking python3-pyasn1 (0.4.2-3) ...\n",
      "Selecting previously unselected package python3-pyasn1-modules.\n",
      "Preparing to unpack .../16-python3-pyasn1-modules_0.2.1-0.2_all.deb ...\n",
      "Unpacking python3-pyasn1-modules (0.2.1-0.2) ...\n",
      "Selecting previously unselected package python3-service-identity.\n",
      "Preparing to unpack .../17-python3-service-identity_16.0.0-2_all.deb ...\n",
      "Unpacking python3-service-identity (16.0.0-2) ...\n",
      "Selecting previously unselected package python3-snappy.\n",
      "Preparing to unpack .../18-python3-snappy_0.5-1.1build2_amd64.deb ...\n",
      "Unpacking python3-snappy (0.5-1.1build2) ...\n",
      "Selecting previously unselected package python3-trie.\n",
      "Preparing to unpack .../19-python3-trie_0.2+ds-1_all.deb ...\n",
      "Unpacking python3-trie (0.2+ds-1) ...\n",
      "Selecting previously unselected package python3-automat.\n",
      "Preparing to unpack .../20-python3-automat_0.6.0-1_all.deb ...\n",
      "Unpacking python3-automat (0.6.0-1) ...\n",
      "Selecting previously unselected package python3-constantly.\n",
      "Preparing to unpack .../21-python3-constantly_15.1.0-1_all.deb ...\n",
      "Unpacking python3-constantly (15.1.0-1) ...\n",
      "Selecting previously unselected package python3-hyperlink.\n",
      "Preparing to unpack .../22-python3-hyperlink_17.3.1-2_all.deb ...\n",
      "Unpacking python3-hyperlink (17.3.1-2) ...\n",
      "Selecting previously unselected package python3-incremental.\n",
      "Preparing to unpack .../23-python3-incremental_16.10.1-3_all.deb ...\n",
      "Unpacking python3-incremental (16.10.1-3) ...\n",
      "Selecting previously unselected package python3-pkg-resources.\n",
      "Preparing to unpack .../24-python3-pkg-resources_39.0.1-2_all.deb ...\n",
      "Unpacking python3-pkg-resources (39.0.1-2) ...\n",
      "Selecting previously unselected package python3-zope.interface.\n",
      "Preparing to unpack .../25-python3-zope.interface_4.3.2-1build2_amd64.deb ...\n",
      "Unpacking python3-zope.interface (4.3.2-1build2) ...\n",
      "Selecting previously unselected package python3-twisted-bin:amd64.\n",
      "Preparing to unpack .../26-python3-twisted-bin_17.9.0-2ubuntu0.1_amd64.deb ...\n",
      "Unpacking python3-twisted-bin:amd64 (17.9.0-2ubuntu0.1) ...\n",
      "Selecting previously unselected package python3-twisted.\n",
      "Preparing to unpack .../27-python3-twisted_17.9.0-2ubuntu0.1_all.deb ...\n",
      "Unpacking python3-twisted (17.9.0-2ubuntu0.1) ...\n",
      "Selecting previously unselected package python3-txaio.\n",
      "Preparing to unpack .../28-python3-txaio_2.8.1-1_all.deb ...\n",
      "Unpacking python3-txaio (2.8.1-1) ...\n",
      "Selecting previously unselected package python3-u-msgpack.\n",
      "Preparing to unpack .../29-python3-u-msgpack_2.1-1_all.deb ...\n",
      "Unpacking python3-u-msgpack (2.1-1) ...\n",
      "Selecting previously unselected package python3-ubjson.\n",
      "Preparing to unpack .../30-python3-ubjson_0.8.5-2build1_amd64.deb ...\n",
      "Unpacking python3-ubjson (0.8.5-2build1) ...\n",
      "Selecting previously unselected package python3-wsaccel.\n",
      "Preparing to unpack .../31-python3-wsaccel_0.6.2-1_amd64.deb ...\n",
      "Unpacking python3-wsaccel (0.6.2-1) ...\n",
      "Selecting previously unselected package python3-autobahn.\n",
      "Preparing to unpack .../32-python3-autobahn_17.10.1+dfsg1-2_all.deb ...\n",
      "Unpacking python3-autobahn (17.10.1+dfsg1-2) ...\n",
      "Selecting previously unselected package python3-colorama.\n",
      "Preparing to unpack .../33-python3-colorama_0.3.7-1_all.deb ...\n",
      "Unpacking python3-colorama (0.3.7-1) ...\n",
      "Selecting previously unselected package python3-click.\n",
      "Preparing to unpack .../34-python3-click_6.7-3_all.deb ...\n",
      "Unpacking python3-click (6.7-3) ...\n",
      "Selecting previously unselected package python3-hkdf.\n",
      "Preparing to unpack .../35-python3-hkdf_0.0.3-3_all.deb ...\n",
      "Unpacking python3-hkdf (0.0.3-3) ...\n",
      "Selecting previously unselected package python3-humanize.\n",
      "Preparing to unpack .../36-python3-humanize_0.5.1-2_all.deb ...\n",
      "Unpacking python3-humanize (0.5.1-2) ...\n",
      "Selecting previously unselected package python3-spake2.\n",
      "Preparing to unpack .../37-python3-spake2_0.7-3_all.deb ...\n",
      "Unpacking python3-spake2 (0.7-3) ...\n",
      "Selecting previously unselected package python3-tqdm.\n",
      "Preparing to unpack .../38-python3-tqdm_4.19.5-1_all.deb ...\n",
      "Unpacking python3-tqdm (4.19.5-1) ...\n",
      "Selecting previously unselected package python3-geoip.\n",
      "Preparing to unpack .../39-python3-geoip_1.3.2-1build4_amd64.deb ...\n",
      "Unpacking python3-geoip (1.3.2-1build4) ...\n",
      "Selecting previously unselected package python3-txtorcon.\n",
      "Preparing to unpack .../40-python3-txtorcon_0.19.3-4_all.deb ...\n",
      "Unpacking python3-txtorcon (0.19.3-4) ...\n",
      "Selecting previously unselected package magic-wormhole.\n",
      "Preparing to unpack .../41-magic-wormhole_0.10.3-1_all.deb ...\n",
      "Unpacking magic-wormhole (0.10.3-1) ...\n",
      "Selecting previously unselected package python3-olefile.\n",
      "Preparing to unpack .../42-python3-olefile_0.45.1-1_all.deb ...\n",
      "Unpacking python3-olefile (0.45.1-1) ...\n",
      "Selecting previously unselected package python3-pam.\n",
      "Preparing to unpack .../43-python3-pam_0.4.2-13.2ubuntu4_amd64.deb ...\n",
      "Unpacking python3-pam (0.4.2-13.2ubuntu4) ...\n",
      "Selecting previously unselected package python3-serial.\n",
      "Preparing to unpack .../44-python3-serial_3.4-2_all.deb ...\n",
      "Unpacking python3-serial (3.4-2) ...\n",
      "Setting up python3-cbor (1.0.0-1) ...\n",
      "Setting up python3-incremental (16.10.1-3) ...\n",
      "Setting up python3-snappy (0.5-1.1build2) ...\n",
      "Setting up python3-ubjson (0.8.5-2build1) ...\n",
      "Setting up python3-pam (0.4.2-13.2ubuntu4) ...\n",
      "Setting up python3-pil:amd64 (5.1.0-1ubuntu0.3) ...\n",
      "Setting up python3-serial (3.4-2) ...\n",
      "Setting up python3-cffi-backend (1.11.5-1) ...\n",
      "Setting up python3-olefile (0.45.1-1) ...\n",
      "Setting up geoip-database (20180315-1) ...\n",
      "Setting up python3-twisted-bin:amd64 (17.9.0-2ubuntu0.1) ...\n",
      "Setting up python3-u-msgpack (2.1-1) ...\n",
      "Setting up python3-constantly (15.1.0-1) ...\n",
      "Setting up python3-idna (2.6-1) ...\n",
      "Setting up python3-tqdm (4.19.5-1) ...\n",
      "Setting up python3-six (1.11.0-2) ...\n",
      "Setting up python3-colorama (0.3.7-1) ...\n",
      "Setting up python3-hkdf (0.0.3-3) ...\n",
      "Setting up python3-pkg-resources (39.0.1-2) ...\n",
      "Setting up libgeoip1:amd64 (1.6.12-1) ...\n",
      "Setting up python3-asn1crypto (0.24.0-1) ...\n",
      "Setting up python3-pyasn1 (0.4.2-3) ...\n",
      "Setting up python3-lz4 (0.10.1+dfsg1-0.2) ...\n",
      "Setting up python3-pyasn1-modules (0.2.1-0.2) ...\n",
      "Setting up python3-nacl (1.1.2-1build1) ...\n",
      "Setting up python3-attr (17.4.0-2) ...\n",
      "Setting up cython3 (0.26.1-0.4) ...\n",
      "Setting up python3-qrcode (5.3-1) ...\n",
      "update-alternatives: using /usr/bin/python3-qr to provide /usr/bin/qr (qr) in auto mode\n",
      "Setting up python3-hyperlink (17.3.1-2) ...\n",
      "Setting up python3-wsaccel (0.6.2-1) ...\n",
      "Setting up python3-automat (0.6.0-1) ...\n",
      "Setting up python3-humanize (0.5.1-2) ...\n",
      "Setting up python3-trie (0.2+ds-1) ...\n",
      "Setting up python3-cryptography (2.1.4-1ubuntu1.3) ...\n",
      "Setting up python3-spake2 (0.7-3) ...\n",
      "Setting up python3-geoip (1.3.2-1build4) ...\n",
      "Setting up python3-click (6.7-3) ...\n",
      "Setting up python3-zope.interface (4.3.2-1build2) ...\n",
      "Setting up python3-openssl (17.5.0-1ubuntu1) ...\n",
      "Setting up python3-service-identity (16.0.0-2) ...\n",
      "Setting up python3-twisted (17.9.0-2ubuntu0.1) ...\n",
      "Setting up python3-txaio (2.8.1-1) ...\n",
      "Setting up python3-txtorcon (0.19.3-4) ...\n",
      "Setting up python3-autobahn (17.10.1+dfsg1-2) ...\n",
      "Setting up magic-wormhole (0.10.3-1) ...\n",
      "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
      "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
      "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!apt update\n",
    "!apt install magic-wormhole"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "inception-v4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
